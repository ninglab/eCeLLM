{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "seed = 1\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "def load_pickle(addr):\n",
    "    with open(addr, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "def dump_pickle(data, addr):\n",
    "    with open(addr, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "def load_json(addr):\n",
    "    with open(addr, 'r') as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "def dump_json(data, addr):\n",
    "    with open(addr, 'w') as f:\n",
    "        json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "import pandas as pd\n",
    "\n",
    "def read_jsonl(addr):\n",
    "    jsonlist = []\n",
    "    with open(addr, \"r\", encoding=\"utf8\") as f:\n",
    "        for item in jsonlines.Reader(f):\n",
    "            jsonlist.append(item)\n",
    "    return jsonlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## answerable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import traceback\n",
    "\n",
    "def process_answerable(df, cats, spl, size):\n",
    "    df_cats = pd.DataFrame()\n",
    "    for cat in cats:\n",
    "        df_cats = pd.concat([df_cats, df[df['category'] == cat]])\n",
    "    try:\n",
    "        df_cats = df_cats.sample(n=size, random_state=seed)\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "    stru_data = []\n",
    "    for index, row in tqdm(df_cats.iterrows(), total=len(df_cats)):\n",
    "        new_entry = {}\n",
    "        new_entry[\"instruction\"] = \"Given a question and the related document, predict if the question is answerable based on the information provided in the document. Output only yes or no.\"\n",
    "        new_entry[\"input\"] = json.dumps({\n",
    "            \"question\": row['questionText'],\n",
    "            \"document\": row['review_snippets']\n",
    "        })\n",
    "        new_entry[\"output\"] = 'yes' if row['is_answerable'] == 1 else 'no'\n",
    "        stru_data.append(new_entry)\n",
    "\n",
    "    if len(cats) > 1:\n",
    "        dir = './stru_data/answerable_mix/'\n",
    "    else:\n",
    "        dir = './stru_data/answerable_OOD/'\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "    dump_json(stru_data, '{}/{}_{}k.json'.format(dir, spl, len(stru_data)//1000))\n",
    "\n",
    "def process_split_answerable(path, cats, spl, size):\n",
    "    qa = read_jsonl('{}/{}-qar.jsonl'.format(path, spl))\n",
    "    df = pd.DataFrame(qa)\n",
    "    process_answerable(df, cats, spl, size)\n",
    "\n",
    "def call_process_answerable(cats, path, train_size, val_size, test_size):\n",
    "    if len(cats) > 1:\n",
    "        process_split_answerable(path, cats, 'train', train_size)\n",
    "        process_split_answerable(path, cats, 'val', val_size)\n",
    "    process_split_answerable(path, cats, 'test', test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 17540.35it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 17350.55it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 17419.87it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 18200.89it/s]\n"
     ]
    }
   ],
   "source": [
    "path = './datasets/productQA'\n",
    "train_size, val_size, test_size = 10000, 1000, 1000\n",
    "call_process_answerable([\"Sports_and_Outdoors\",\"Tools_and_Home_Improvement\"], path, train_size, val_size, test_size)\n",
    "call_process_answerable([\"Cell_Phones_and_Accessories\"], path, train_size, val_size, test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import traceback\n",
    "\n",
    "def process_generation(df, cats, spl, size):\n",
    "    df_cats = pd.DataFrame()\n",
    "    for cat in cats:\n",
    "        df_cats = pd.concat([df_cats, df[df['category'] == cat]])\n",
    "    df_cats = df_cats[(df_cats[\"questionType\"] == \"descriptive\") & (df_cats[\"is_answerable\"] == 1)]\n",
    "    df_cats = df_cats.sample(frac=1, random_state=seed)\n",
    "    stru_data = []\n",
    "    for index, row in tqdm(df_cats.iterrows(), total=len(df_cats)):\n",
    "        answers = row[\"answers\"]\n",
    "        gt = answers[0]\n",
    "        gtscore = 0\n",
    "        for answer in answers:\n",
    "            if answer[\"helpful\"][1] == 0:\n",
    "                continue\n",
    "            score = answer[\"helpful\"][0]\n",
    "            if score > gtscore:\n",
    "                gtscore = score\n",
    "                gt = answer\n",
    "        if gtscore == 0:\n",
    "            continue\n",
    "        new_entry = {}\n",
    "        new_entry[\"instruction\"] = \"Given a question and the related document, and generate the answer to the question based on the information provided in the document.\"\n",
    "        new_entry[\"input\"] = json.dumps({\n",
    "            'question': row['questionText'],\n",
    "            'document': row['review_snippets']\n",
    "        })\n",
    "        new_entry[\"output\"] = gt[\"answerText\"]\n",
    "        stru_data.append(new_entry)\n",
    "        if len(stru_data) == size:\n",
    "            break\n",
    "\n",
    "    if len(cats) > 1:\n",
    "        dir = './stru_data/generation_mix/'\n",
    "    else:\n",
    "        dir = './stru_data/generation_OOD/'\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "    print(len(stru_data))\n",
    "    dump_json(stru_data, '{}/{}_{}k.json'.format(dir, spl, len(stru_data)//1000))\n",
    "\n",
    "def process_split_generation(path, cats, spl, size):\n",
    "    qa = read_jsonl('{}/{}-qar.jsonl'.format(path, spl))\n",
    "    df = pd.DataFrame(qa)\n",
    "    process_generation(df, cats, spl, size)\n",
    "\n",
    "def call_process_generation(cats, path, train_size, val_size, test_size):\n",
    "    if len(cats) > 1:\n",
    "        process_split_generation(path, cats, 'train', train_size)\n",
    "        process_split_generation(path, cats, 'val', val_size)\n",
    "    process_split_generation(path, cats, 'test', test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 18260/148443 [00:00<00:06, 18665.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 1811/18820 [00:00<00:00, 18614.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 1791/19245 [00:00<00:00, 18060.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 2062/2870 [00:00<00:00, 21455.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "path = './datasets/productQA'\n",
    "train_size, val_size, test_size = 10000, 1000, 1000\n",
    "call_process_generation([\"Electronics\",\"Home_and_Kitchen\"], path, train_size, val_size, test_size)\n",
    "call_process_generation([\"Cell_Phones_and_Accessories\"], path, train_size, val_size, test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## diverse instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diverse_instruction(path, instrs, unseen):\n",
    "    for file in os.listdir(path):\n",
    "        data = load_json(os.path.join(path, file))\n",
    "        for entry in data:\n",
    "            entry[\"instruction\"] = random.sample(instrs, k=1)[0]\n",
    "        if not os.path.exists(os.path.join('{}_di'.format(path))):\n",
    "            os.makedirs(os.path.join('{}_di'.format(path)))\n",
    "        dump_json(data, os.path.join('{}_di'.format(path), file))\n",
    "    \n",
    "        if file.startswith('test'):\n",
    "            for entry in data:\n",
    "                entry[\"instruction\"] = unseen\n",
    "            if not os.path.exists(os.path.join('{}_ui'.format(path))):\n",
    "                os.makedirs(os.path.join('{}_ui'.format(path)))\n",
    "            dump_json(data, os.path.join('{}_ui'.format(path), file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict whether it is possible to answer the given question using the supporting document, and output a yes or no response.\n"
     ]
    }
   ],
   "source": [
    "random.seed(seed)\n",
    "base_instr = \"Given a question and the related document, predict if the question is answerable based on the information provided in the document. Output only yes or no.\"\n",
    "instrs = [\n",
    "\"Evaluate the answerability of a question by analyzing the related document, outputting yes if the document contains information addressing the question, and no otherwise.\",\n",
    "\"Predict whether it is possible to answer the given question using the supporting document, and output a yes or no response.\",\n",
    "\"Analyze a question and its supporting document. Predicting answerability based on the information provided in the document. Output yes if the document contains relevant information to answer the question, otherwise output no.\",\n",
    "\"Given a question and its related document, determine if the question is answerable by analyzing the information in the document. Output yes if the document addresses the question, or no otherwise.\",\n",
    "\"Output yes if the supporting document can answer the given question. Otherwise, output no.\"\n",
    "]\n",
    "unseen = random.sample(instrs, k=1)[0]\n",
    "instrs.remove(unseen)\n",
    "print(unseen)\n",
    "instrs.append(base_instr)\n",
    "diverse_instruction('./stru_data/answerable_mix', instrs, unseen)\n",
    "diverse_instruction('./stru_data/answerable_OOD', instrs, unseen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## few-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def few_shot(path):\n",
    "    test_data = load_json('{}/test_1k.json'.format(path))\n",
    "    try:\n",
    "        train_data = load_json('{}/train_10k.json'.format(path))\n",
    "    except:\n",
    "        train_data = load_json('./stru_data/answerable_mix/train_10k.json')\n",
    "    few_shot = []\n",
    "    for index, entry in enumerate(test_data):\n",
    "        new_entry = {}\n",
    "        new_entry['instruction'] = entry['instruction']\n",
    "        new_entry['example'] = json.dumps({\n",
    "            'input': train_data[index]['input'],\n",
    "            'output': train_data[index]['output']\n",
    "        })\n",
    "        new_entry['test example'] = json.dumps({\n",
    "            'input': entry['input'],\n",
    "            'output': entry[\"output\"]\n",
    "        })\n",
    "        few_shot.append(new_entry)\n",
    "    if not os.path.exists('{}_few_shot'.format(path)):\n",
    "        os.makedirs('{}_few_shot'.format(path))\n",
    "    dump_json(few_shot, '{}_few_shot/test_1k.json'.format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot('./stru_data/answerable_mix')\n",
    "few_shot('./stru_data/answerable_mix_di')\n",
    "few_shot('./stru_data/answerable_OOD')\n",
    "few_shot('./stru_data/answerable_OOD_di')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generation - di & few-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilize the information provided in the supporting document to generate an answer to the given question.\n"
     ]
    }
   ],
   "source": [
    "random.seed(seed)\n",
    "base_instr = \"Given a question and the related document, and generate the answer to the question based on the information provided in the document.\"\n",
    "instrs = [\n",
    "\"Generate an answer to the question by utilizing the information contained in the document.\",\n",
    "\"Utilize the information provided in the supporting document to generate an answer to the given question.\",\n",
    "\"Extract information from the supporting document to answer the given question.\",\n",
    "\"Answer the given question using the supporting document.\",\n",
    "\"Answer the given question by extracting information from the supporting document.\"\n",
    "]\n",
    "unseen = random.sample(instrs, k=1)[0]\n",
    "instrs.remove(unseen)\n",
    "print(unseen)\n",
    "instrs.append(base_instr)\n",
    "diverse_instruction('./stru_data/generation_mix', instrs, unseen)\n",
    "diverse_instruction('./stru_data/generation_OOD', instrs, unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def few_shot(path):\n",
    "    test_data = load_json('{}/test_1k.json'.format(path))\n",
    "    try:\n",
    "        train_data = load_json('{}/train_10k.json'.format(path))\n",
    "    except:\n",
    "        train_data = load_json('./stru_data/generation_mix/train_10k.json')\n",
    "    few_shot = []\n",
    "    for index, entry in enumerate(test_data):\n",
    "        new_entry = {}\n",
    "        new_entry['instruction'] = entry['instruction']\n",
    "        new_entry['example'] = json.dumps({\n",
    "            'input': train_data[index]['input'],\n",
    "            'output': train_data[index]['output']\n",
    "        })\n",
    "        new_entry['test example'] = json.dumps({\n",
    "            'input': entry['input'],\n",
    "            'output': entry[\"output\"]\n",
    "        })\n",
    "        few_shot.append(new_entry)\n",
    "    if not os.path.exists('{}_few_shot'.format(path)):\n",
    "        os.makedirs('{}_few_shot'.format(path))\n",
    "    dump_json(few_shot, '{}_few_shot/test_1k.json'.format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot('./stru_data/generation_mix')\n",
    "few_shot('./stru_data/generation_mix_di')\n",
    "few_shot('./stru_data/generation_OOD')\n",
    "few_shot('./stru_data/generation_OOD_di')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm4rec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
