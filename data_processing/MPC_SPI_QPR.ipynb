{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "seed = 1\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "def load_pickle(addr):\n",
    "    with open(addr, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "def dump_pickle(data, addr):\n",
    "    with open(addr, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "def load_json(addr):\n",
    "    with open(addr, 'r') as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "def dump_json(data, addr):\n",
    "    with open(addr, 'w') as f:\n",
    "        json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import unicodedata\n",
    "import traceback\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def nor_unicode(text):\n",
    "    return str(unicodedata.normalize('NFKD', text).encode('ascii', 'ignore'), encoding = \"utf-8\")\n",
    "\n",
    "def load_raw_data(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        df_task = pd.DataFrame(json.load(f))\n",
    "    df_train = df_task[df_task[\"split\"] == \"train\"]\n",
    "    df_test_dev = df_task[df_task[\"split\"] == \"test\"]\n",
    "    df_test = df_test_dev.sample(frac=0.5, random_state=seed)\n",
    "    df_val = pd.concat([df_test_dev, df_test, df_test]).drop_duplicates(keep=False)\n",
    "    return df_train, df_val, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_query(df, spl, n):\n",
    "    exampleids = set()\n",
    "    rankinglist = []\n",
    "    df_1 = df[df['small_version'] == 1]\n",
    "    queries = df_1['query'].unique().tolist()\n",
    "    while len(rankinglist) < n:\n",
    "        try:\n",
    "            query = random.sample(queries, 1)[0]    # random query\n",
    "            rank = []    # items in this ranking set\n",
    "            labels = set()    # unique labels in this ranking set\n",
    "            items = df_1[(df_1['query'] == query)]\n",
    "            length = random.randint(2,4)    # number of items in this ranking set\n",
    "            if len(items) == 0 or len(items['esci_label'].unique()) < length:    # if there are enough unique items\n",
    "                continue\n",
    "            esci = ['E','S','C','I']    # candidate labels\n",
    "            pair = []\n",
    "            while len(labels) < length:\n",
    "                label = random.sample(esci, 1)[0]\n",
    "                try:\n",
    "                    item = items[items['esci_label'] == label].sample(n=1, random_state=seed).iloc[0]\n",
    "                    pair.append(item['example_id'])\n",
    "                    labels.add(label)\n",
    "                    rank.append(item)\n",
    "                    esci.remove(label)\n",
    "                except:\n",
    "                    esci.remove(label)\n",
    "                    continue\n",
    "            pair_set = tuple(sorted(pair))\n",
    "            if pair_set not in exampleids:\n",
    "                rankinglist.append(rank)\n",
    "                exampleids.add(pair_set)\n",
    "        except:\n",
    "            traceback.print_exc()\n",
    "\n",
    "    dump_pickle(rankinglist, './raw_data/rankinglist_{}_{}k.pickle'.format(spl, n//1000))\n",
    "    return rankinglist\n",
    "\n",
    "def process_rank(df, spl, size):\n",
    "    dir = './raw_data/rankinglist_{}_{}k.pickle'.format(spl, size//1000)\n",
    "    if not os.path.exists(dir):\n",
    "        rankinglist = rank_query(df, spl, size)\n",
    "    else:\n",
    "        rankinglist = load_pickle(dir)\n",
    "    stru_data = []\n",
    "    label_list = []\n",
    "    for rank in tqdm(rankinglist):\n",
    "        query = nor_unicode(rank[0]['query'])\n",
    "        # random.shuffle(rank)\n",
    "        products = []\n",
    "        labels = []\n",
    "        output = ['','','','']\n",
    "        for i in range(len(rank)):\n",
    "            entry = rank[i]\n",
    "            products.append([chr(65+i), nor_unicode(entry['product_title']), entry['esci_label']])\n",
    "        for prod in products:\n",
    "            labels.append(prod[2])\n",
    "            if prod[2] == 'E':\n",
    "                output[0] = prod[0]\n",
    "            elif prod[2] == 'S':\n",
    "                output[1] = prod[0]\n",
    "            elif prod[2] == 'C':\n",
    "                output[2] = prod[0]\n",
    "            else:\n",
    "                output[3] = prod[0]\n",
    "        new_entry = {}\n",
    "        new_entry[\"instruction\"] = \"Given a query and a list of products denoted as A, B, C, ... with their titles, rank the products according to their relevance to the query. Output only a ranked list in which the most relevant product is at the top of the list.\"\n",
    "        new_entry[\"input\"] = json.dumps({\n",
    "            'query': query,\n",
    "            'product list': [(str(pr[0]) + ': ' + str(pr[1])) for pr in products]\n",
    "        })\n",
    "        new_entry[\"output\"] = ','.join(list(''.join(output))).strip(',')\n",
    "        stru_data.append(new_entry)\n",
    "        label_list.append(labels)\n",
    "\n",
    "    dir = './stru_data/rank'\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "    dump_json(stru_data, '{}/{}_{}k.json'.format(dir, spl, len(stru_data)//1000))\n",
    "    dump_json(label_list, '{}/label_{}_{}k.json'.format(dir, spl, len(stru_data)//1000))\n",
    "    # return stru_data\n",
    "\n",
    "def process_split_rank(train, val, test, train_size, val_size, test_size):\n",
    "    process_rank(train, 'train', train_size)\n",
    "    process_rank(val, 'val', val_size)\n",
    "    process_rank(test, 'test', test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multiclass product classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mulclass(df, spl, size):\n",
    "    df = df.sample(n=size, random_state=seed+1)\n",
    "    labels = {'E':'A: The product is relevant to the query, and satisfies all the query specifications.',\n",
    "          'S':'B: The product is somewhat relevant. It fails to fulfill some aspects of the query but the product can be used as a functional substitute.',\n",
    "          'C':'C: The product does not fulfill the query, but could be used in combination with a product exactly matching the query.',\n",
    "          'I':'D: The product is irrelevant to the query.'}\n",
    "    stru_data = []\n",
    "    baseline = []\n",
    "    for index, row in df.iterrows():\n",
    "        query = nor_unicode(row['query'])\n",
    "        title = nor_unicode(row['product_title'])\n",
    "        new_entry = {}\n",
    "        new_entry[\"instruction\"] = \"What is the relevance between the query and the product title below? Answer from one of the options.\"\n",
    "        new_entry[\"input\"] = json.dumps({\n",
    "            'query': query,\n",
    "            'product title': title\n",
    "        })\n",
    "        new_entry['options'] = json.dumps([\n",
    "            'A: The product is relevant to the query, and satisfies all the query specifications.',\n",
    "            'B: The product is somewhat relevant. It fails to fulfill some aspects of the query but the product can be used as a functional substitute.',\n",
    "            'C: The product does not fulfill the query, but could be used in combination with a product exactly matching the query.',\n",
    "            'D: The product is irrelevant to the query.'])\n",
    "        new_entry[\"output\"] = labels[row['esci_label']]\n",
    "        stru_data.append(new_entry)\n",
    "        baseline.append([query, title, row['esci_label']])\n",
    "    \n",
    "    dir = './stru_data/multi_classification'\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "    dump_json(stru_data, '{}/{}_{}k.json'.format(dir, spl, len(stru_data)//1000))\n",
    "    dump_json(baseline, './baseline/data_mc/{}_{}k.json'.format(spl,len(stru_data)//1000))\n",
    "    # return stru_data\n",
    "\n",
    "def process_split_mulclass(train, val, test, train_size, val_size, test_size):\n",
    "    process_mulclass(train, 'train', train_size)\n",
    "    process_mulclass(val, 'val', val_size)\n",
    "    process_mulclass(test, 'test', test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## substitute identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_iden(df, spl, size):\n",
    "    df = df.sample(n=size, random_state=seed)\n",
    "    stru_data = []\n",
    "    for index, row in df.iterrows():\n",
    "        label = 'S'\n",
    "        new_entry = {}\n",
    "        new_entry[\"instruction\"] = \"Given a query and a product, identify if the product is somewhat relevant to the query. It fails to fulfill some aspects of the query but the product can be used as a functional substitute. Only output yes or no.\"\n",
    "        new_entry[\"input\"] = json.dumps({\n",
    "            'query': nor_unicode(row['query']),\n",
    "            'product': nor_unicode(row['product_title'])\n",
    "        })\n",
    "        new_entry[\"output\"] = 'yes' if row['esci_label'] == label else 'no'\n",
    "        stru_data.append(new_entry)\n",
    "\n",
    "    dir = './stru_data/s_identification'\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "    dump_json(stru_data, '{}/{}_{}k.json'.format(dir, spl, len(stru_data)//1000))\n",
    "\n",
    "def process_split_iden(train, val, test, train_size, val_size, test_size):\n",
    "    process_iden(train, 'train', train_size)\n",
    "    process_iden(val, 'val', val_size)\n",
    "    process_iden(test, 'test', test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.language import Language\n",
    "from spacy_langdetect import LanguageDetector\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import pandas as pd\n",
    "import traceback\n",
    "\n",
    "def get_lang_detector(nlp, name):\n",
    "    return LanguageDetector()\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "Language.factory(\"language_detector\", func=get_lang_detector)\n",
    "nlp.add_pipe('language_detector', last=True)\n",
    "def is_en(text):\n",
    "    if not text or nlp(text)._.language['language'] == 'en':\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_examples = pd.read_parquet('./datasets/shopping_queries_dataset/shopping_queries_dataset_examples.parquet')\n",
    "df_products = pd.read_parquet('./datasets/shopping_queries_dataset/shopping_queries_dataset_products.parquet')\n",
    "df_sources = pd.read_csv(\"./datasets/shopping_queries_dataset/shopping_queries_dataset_sources.csv\")\n",
    "df_examples_products = pd.merge(\n",
    "    df_examples,\n",
    "    df_products,\n",
    "    how='left',\n",
    "    left_on=['product_locale','product_id'],\n",
    "    right_on=['product_locale', 'product_id']\n",
    ")\n",
    "df_task_2 = df_examples_products[df_examples_products['product_locale'] == 'us']\n",
    "df_task_2.fillna(\"\", inplace=True)\n",
    "df_task_2['product_title'].replace('\\n',' ', regex=True, inplace=True)\n",
    "df_task_2['product_title'].replace('\\r',' ', regex=True, inplace=True)\n",
    "df_task_2['product_title'].replace('\\s',' ', regex=True, inplace=True)\n",
    "df_task_2['product_title'].replace('</p>',' ', regex=True, inplace=True)\n",
    "df_task_2['product_title'].replace('<p>',' ', regex=True, inplace=True)\n",
    "df_task_2['product_title'].replace('<br>',' ', regex=True, inplace=True)\n",
    "df_task_2['product_title'].replace('</br>',' ', regex=True, inplace=True)\n",
    "\n",
    "list_en = []\n",
    "for index, row in tqdm(df_task_2.iterrows(), total=len(df_task_2), mininterval=20):\n",
    "    if is_en(row['query']) and is_en(row['product_title']):\n",
    "        list_en.append(row.to_dict())\n",
    "\n",
    "with open('./datasets/query_dataset.json', 'w', encoding=\"utf-8\") as f:\n",
    "    json.dump(list_en, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 29699.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 30297.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 31201.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "random.seed(seed)\n",
    "path = './datasets/query_dataset.json'\n",
    "train, val, test = load_raw_data(path)\n",
    "train_size, val_size, test_size = 10000, 1000, 1000\n",
    "process_split_mulclass(train, val, test, train_size, val_size, test_size)\n",
    "process_split_iden(train, val, test, train_size, val_size, test_size)\n",
    "process_split_rank(train, val, test, train_size, val_size, test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## diverse instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diverse_instruction(path, instrs, unseen):\n",
    "    for file in os.listdir(path):\n",
    "        data = load_json(os.path.join(path, file))\n",
    "        for entry in data:\n",
    "            entry[\"instruction\"] = random.sample(instrs, k=1)[0]\n",
    "        if not os.path.exists(os.path.join('{}_di'.format(path))):\n",
    "            os.makedirs(os.path.join('{}_di'.format(path)))\n",
    "        dump_json(data, os.path.join('{}_di'.format(path), file))\n",
    "    \n",
    "        if file.startswith('test'):\n",
    "            for entry in data:\n",
    "                entry[\"instruction\"] = unseen\n",
    "            if not os.path.exists(os.path.join('{}_ui'.format(path))):\n",
    "                os.makedirs(os.path.join('{}_ui'.format(path)))\n",
    "            dump_json(data, os.path.join('{}_ui'.format(path), file))\n",
    "\n",
    "def run_di(instrs, base_instr, path):\n",
    "    unseen = random.sample(instrs, k=1)[0]\n",
    "    instrs.remove(unseen)\n",
    "    print(unseen)\n",
    "    instrs.append(base_instr)\n",
    "    diverse_instruction(path, instrs, unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate the query against each product's title, determine the relevance between the query and the product, and organize the products in descending order of relevance, ensuring that the product with the highest relevance is positioned at the top of the list.\n",
      "Compare the query and the product title to determine if the product fully meets the query specifications. Choose the option that best describes the relevance between them.\n",
      "Assess whether the product is a substitute for the query and provide a yes or no response.\n"
     ]
    }
   ],
   "source": [
    "random.seed(seed)\n",
    "base_rank = \"Given a query and a list of products denoted as A, B, C, ... with their titles, rank the products according to their relevance to the query. Output only a ranked list in which the most relevant product is at the top of the list.\"\n",
    "instrs_rank = [\n",
    "\"Evaluate each product title in the given list, assess its relevance to the given query, and then arrange the products in descending order of relevance, with the most relevant product at the top of the ranked list.\",\n",
    "\"Evaluate the query against each product's title, determine the relevance between the query and the product, and organize the products in descending order of relevance, ensuring that the product with the highest relevance is positioned at the top of the list.\",\n",
    "\"Rank the products A, B, C, ... based on their relevance to the provided query, and produce a ranked list with the most relevant product positioned at the top of the list.\",\n",
    "\"Analyze the query and each product title. Sort the products in descending order based on their relevance to the query. The most relevant product should be at the top of the list, and output the ranked list.\",\n",
    "\"Evaluate the relevance of each product title in the input to the given query, and then sort the products in descending order of relevance, placing the most relevant product at the top of the ranked list.\"\n",
    "]\n",
    "base_mc = \"What is the relevance between the query and the product title below? Answer from one of the options.\"\n",
    "instrs_mc = [\n",
    "\"Analyze the query and product title to determine the relevance between the query and product, and select the appropriate option from the provided options.\",\n",
    "\"Evaluate the relevance between the query and product title, and choose the most accurate option from the given options.\",\n",
    "\"Analyze the query and product title to assess the level of relevance between them, and then output the corresponding option that best describes this relevance.\",\n",
    "\"Determine the relevance between the query and the product title provided, and select your response from one of the available options.\",\n",
    "\"Compare the query and the product title to determine if the product fully meets the query specifications. Choose the option that best describes the relevance between them.\"\n",
    "]\n",
    "base_iden = \"Given a query and a product, identify if the product is somewhat relevant to the query. It fails to fulfill some aspects of the query but the product can be used as a functional substitute. Only output yes or no.\"\n",
    "instrs_iden = [\n",
    "\"Assess whether the product is a substitute for the query and provide a yes or no response.\",\n",
    "\"Answer yes if the product is a substitute for the query and no otherwise.\",\n",
    "\"Please respond with yes if the product is a suitable substitute for the query, and no if it is not.\",\n",
    "\"Check if a product can function as a substitute for a given query, even if it doesn't fully meet all requirements. Output yes if it can or no otherwise.\",\n",
    "\"Assess the relevance of a product to a given query by determining if it can function as a substitute, despite not fully meeting certain aspects of the query. Provide a binary output of yes or no based on this evaluation.\"\n",
    "]\n",
    "\n",
    "run_di(instrs_rank, base_rank, './stru_data/rank')\n",
    "run_di(instrs_mc, base_mc, './stru_data/multi_classification')\n",
    "run_di(instrs_iden, base_iden, './stru_data/s_identification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## few-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def few_shot(path):\n",
    "    test_data = load_json('{}/test_1k.json'.format(path))\n",
    "    train_data = load_json('{}/train_10k.json'.format(path))\n",
    "    few_shot = []\n",
    "    for index, entry in enumerate(test_data):\n",
    "        new_entry = {}\n",
    "        new_entry['instruction'] = entry['instruction']\n",
    "        new_entry['example'] = json.dumps({\n",
    "            'input': train_data[index]['input'],\n",
    "            'output': train_data[index]['output']\n",
    "        })\n",
    "        new_entry['test example'] = json.dumps({\n",
    "            'input': entry['input'],\n",
    "            'output': entry[\"output\"]\n",
    "        })\n",
    "        few_shot.append(new_entry)\n",
    "    if not os.path.exists('{}_few_shot'.format(path)):\n",
    "        os.makedirs('{}_few_shot'.format(path))\n",
    "    dump_json(few_shot, '{}_few_shot/test_1k.json'.format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def few_shot_woption(path):\n",
    "    test_data = load_json('{}/test_1k.json'.format(path))\n",
    "    train_data = load_json('{}/train_10k.json'.format(path))\n",
    "    few_shot = []\n",
    "    for index, entry in enumerate(test_data):\n",
    "        new_entry = {}\n",
    "        new_entry['instruction'] = entry['instruction']\n",
    "        new_entry['example'] = json.dumps({\n",
    "            'input': train_data[index]['input'],\n",
    "            'options': train_data[index]['options'],\n",
    "            'output': train_data[index]['output']\n",
    "        })\n",
    "        new_entry['test example'] = json.dumps({\n",
    "            'input': entry['input'],\n",
    "            'options': entry['options'],\n",
    "            'output': entry[\"output\"]\n",
    "        })\n",
    "        few_shot.append(new_entry)\n",
    "    if not os.path.exists('{}_few_shot'.format(path)):\n",
    "        os.makedirs('{}_few_shot'.format(path))\n",
    "    dump_json(few_shot, '{}_few_shot/test_1k.json'.format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_woption('./stru_data/multi_classification_di')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot('./stru_data/rank')\n",
    "few_shot('./stru_data/rank_di')\n",
    "few_shot('./stru_data/s_identification')\n",
    "few_shot('./stru_data/s_identification_di')\n",
    "few_shot_woption('./stru_data/multi_classification')\n",
    "few_shot_woption('./stru_data/multi_classification_di')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm4rec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
