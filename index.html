<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Short description of the paper that could be used in search results">
    <meta name="keywords" content="keyword1,keyword2">
    <meta name="author" content="">
    <title>eCeLLM</title>
    <link rel="stylesheet" href="style.css?">
    <!--/ PrismJS code highlighting \-->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/themes/prism.min.css" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/prism.min.js">
    </script>
    <script src="https://cdn.jsdelivr.net/npm/prismjs-bibtex@2.0.1/prism-bibtex.js"
            integrity="sha256-+dK6uqUp/DnP6ef97s8XcoynBnGe5vM5gvBECH0EB3U=" crossorigin="anonymous">
    </script>
    <!--\ PrismJS code highlighting /-->
</head>
<body>
    <script>
    function activate(e) {
        // borrowed from https://stackoverflow.com/questions/26959219/javascript-onclick-addclass
        var litems = document.getElementsByTagName('li');
        for (i = 0; i < litems.length; i++) {
            if(litems[i].getAttribute("data-tabgroup") == e.getAttribute("data-tabgroup"))
                litems[i].classList.remove('active');
        }
        e.classList.add('active');
    }
    </script>
    <header>
        <h1>eCeLLM: Generalizing Large Language Models for E-commerce from Large-scale, High-quality Instruction Data</h1>
        <ul class="authors">
        </ul>
        <ul class="affiliations">
        </ul>
        <ul class="emails">
        </ul>
    </header>
    <nav>
        <ul class="navigation">
                <a href="http://www.example.com"><li>
                    <img src="icons/huggingface.svg" height="20px" alt="Model">&ensp;
                    <span>Model</span>
                </li></a>
                <a href="https://huggingface.co/datasets/xin10/ECInstruct"><li>
                    <img src="icons/huggingface.svg" height="20px" alt="Data">&ensp;
                    <span>Data</span>
                </li></a>
                <a href="https://github.com/ninglab/eCeLLM"><li>
                    <img src="icons/github-white.svg" height="20px" alt="Code">&ensp;
                    <span>Code</span>
                </li></a>
                <a href="http://www.example.com"><li>
                    <img src="icons/arxiv.svg" height="20px" alt="Paper">&ensp;
                    <span>Paper</span>
                </li></a>
        </ul>
    </nav>
    <main>
                <section>
                    <h2 class="centering">Abstract</h2>
                    <p  class="justified">With tremendous efforts on developing effective e-commerce models, conventional e-commerce models show limited success in generalist e-commerce modeling, and suffer from unsatisfactory performance on new users and new products â€” a typical out-of-domain generalization challenge. Meanwhile, large language models (LLMs) demonstrate outstanding performance in generalist modeling and out-of-domain generalizability in many fields. Toward fully unleashing their power for e-commerce, in this paper, we construct ECInstruct, the first open-sourced, large-scale, and high-quality benchmark instruction dataset for e-commerce. Leveraging ECInstruct, we develop eCeLLM, a series of e-commerce LLMs, by instruction-tuning general-purpose LLMs. Our comprehensive experiments and evaluation demonstrate that eCeLLM models substantially outperform baseline models, including the most advanced GPT-4, and the state-of-the-art task-specific models in in-domain evaluation. Moreover, eCeLLM exhibits excellent generalizability to out-of-domain settings, including unseen products and unseen instructions, highlighting its superiority as a generalist e-commerce model. Both the ECInstruct dataset and the eCeLLM models show great potential in empowering versatile and effective LLMs for e-commerce.</p>
                </section>
            
            


            
            <section>
                <h2 class="centering">Overall scheme of eCeLLM instruction-tuned with ECInstruct</h2>
                
                <img src="overview.svg" alt="Overview Figure">
                
            </section>
            


            
            
            <section>
                <h2 class="centering">ECInstruct Dataset</h2>
                <p class="justified">ECInstruct covers 116,528 samples from 10 real and widely performed e-commerce tasks of 4 categories. Each data sample comprises an instruction, an input, and an output. Some samples also incorporate a list of options. All the 10 tasks have in-domain (IND) test samples, and 6 tasks also have out-of-domain (OOD) test samples which consist of products unseen in the training samples of the respective tasks. ECInstruct undergoes rigorous and thorough scrutiny and is carefully crafted to enable a wide spectrum of empirical testing and exploration, including IND evaluation, OOD evaluation, and task-specific studies. Particularly, ECInstruct includes 3 tasks for product understanding: (1) attribute value extraction (AVE), (2) product matching (PM) and (3) product relation prediction (PRP). For user understanding, ECInstruct includes (4) sentiment analysis (SA) and (5) sequential recommendation (SR). ECInstruct also covers 3 query product matching tasks: (6) multi-class product classification (MPC), (7) product substitute identification (PSI), and (8) query-product ranking (QPR). For product question answering, ECInstruct contains the tasks of (9) answerability prediction (AP) and (10) answer generation (AG).</p>
                <iframe width="100%" name="/eCeLLM/tables/task_data.html" title="Table of results generated by htlatex"  style="height:400px" src="/eCeLLM/tables/task_data.html"></iframe>
                <p class="justified">Table above summarizes the tasks in ECInstruct and their data sources. More details are available in Appendix A of our paepr.</p>
            </section>


            
            

            <section>
                <h2 class="centering">Overall Performance</h2>
                
                <ul class="tabs">
                        <a href="/eCeLLM/tables/overall_performance_indomain.html" target="tabs1"><li class="active" data-tabgroup="tabs1" onclick="activate(this)">IND</li></a>
                        <a href="/eCeLLM/tables/overall_performance_OOD.html" target="tabs1"><li class="" data-tabgroup="tabs1" onclick="activate(this)">OOD</li></a>
                </ul>
                <iframe width="100%" frameborder="0" title="tab window frame"  style="height:300px" name="tabs1" src="/eCeLLM/tables/overall_performance_indomain.html"></iframe>
                <p class="justified">In the tables, &quotF1*&quot, &quotMacro F1&quot, &quotF1&quot, &quotHR@1&quot, &quotAccuracy&quot, &quotNDCG&quot and &quotF<sub>BERT</sub>&quot are the primary evaluation metrics in respective tasks (Appendix A). For each task, the best baseline performance is <u>underlined</u>, and the overall best performance is in <b>bold</b>. The row &quotimprovement&quot presents the percentage improvement of the best-performing eCeLLM model over the best-performing baseline model (<u>underlined</u>) in each task. We also include the average ('avg') improvement across all the tasks in the table. Overall, our experimental results demonstrate the following findings: eCeLLM models substantially outperform baseline models, including the most advanced GPT-4 Turbo and the state-of-the-art (SoTA) task-specific models, on almost all the 10 tasks in IND evaluation. On average, eCeLLM models show a substantial improvement of 10.7% over the best baseline models. Moreover, eCeLLM exhibits excellent generalizability to OOD settings, highlighting its superiority as a generalist e-commerce model. Particularly, eCeLLM models establish an improvement of 9.3% over the best baselines on the OOD (new) products. These results indicate the great potential of both the ECInstruct dataset and the eCeLLM models in empowering versatile and effective LLMs for e-commerce, and validate the potential of LLMs in doing e-commerce tasks.</p>
            </section>

            
            

            <section>
                <h2 class="centering">Complete Results on Each Task</h2>
                
                <ul class="tabs">
                        <a href="/eCeLLM/tables/results_AVE.html" target="tabs2"><li class="" data-tabgroup="tabs2" onclick="activate(this)">AVE</li></a>
                        <a href="/eCeLLM/tables/results_IRP.html" target="tabs2"><li class="" data-tabgroup="tabs2" onclick="activate(this)">PRP</li></a>
                        <a href="/eCeLLM/tables/results_EM.html" target="tabs2"><li class="" data-tabgroup="tabs2" onclick="activate(this)">PM</li></a>
                        <a href="/eCeLLM/tables/results_SA.html" target="tabs2"><li class="" data-tabgroup="tabs2" onclick="activate(this)">SA</li></a>
                        <a href="/eCeLLM/tables/results_MPC.html" target="tabs2"><li class="" data-tabgroup="tabs2" onclick="activate(this)">MPC</li></a>
                        <a href="/eCeLLM/tables/results_PSI.html" target="tabs2"><li class="" data-tabgroup="tabs2" onclick="activate(this)">PSI</li></a>
                        <a href="/eCeLLM/tables/results_AP.html" target="tabs2"><li class="" data-tabgroup="tabs2" onclick="activate(this)">AP</li></a>
                        <a href="/eCeLLM/tables/results_AG.html" target="tabs2"><li class="active" data-tabgroup="tabs2" onclick="activate(this)">AG</li></a>
                        <a href="/eCeLLM/tables/results_SR_QPR.html" target="tabs2"><li class="" data-tabgroup="tabs2" onclick="activate(this)">SR and QPR</li></a>
                </ul>
                <iframe width="100%" frameborder="0" title="tab window frame"  style="height:500px" name="tabs2" src="/eCeLLM/tables/results_AG.html"></iframe>
                <p class="justified">Overall, these tables show that eCeLLM models fine-tuned on ECInstruct outperform the general-purpose LLMs and SoTA task-specific models in the IND test. Meanwhile, the eCeLLM exhibits good generalizability to the OOD data. Because of the high-quality ECInstruct, eCeLLM achieves remarkable performance with different base models. Note that #failed in tables represents the number of failure cases that we cannot extract meaningful results from the model output.</p>
            </section>

            
            


            <section>
                <h2>Cite Our Work</h2>
                <p>Please cite our paper if you use our code, data, or models:</p>
                <pre data-src="bibtex.bib"></pre>
            </section>
    </main>
    <footer class="centering">
        <p>Copyright 2024 the authors.&emsp;This work is licensed under a Creative Commons Attribution 4.0 International License. <a href="https://creativecommons.org/licenses/by/4.0">License Information</a>&emsp;</p>
        <p><a href="https://github.com/frazierbaker/project-template">Website template</a> by Frazier N. Baker,
        licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0">CC-BY-SA 4.0</a>.
        Color scheme trademarked by <a href="https://osu.edu">The Ohio State University</a>.
        </p>
    </footer>
</body>
</html>

