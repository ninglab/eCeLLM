{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "seed = 1\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "def load_pickle(addr):\n",
    "    with open(addr, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "def dump_pickle(data, addr):\n",
    "    with open(addr, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "def load_json(addr):\n",
    "    with open(addr, 'r') as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "def dump_json(data, addr):\n",
    "    with open(addr, 'w') as f:\n",
    "        json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')       \n",
    "    for l in g:\n",
    "        yield json.loads(l)\n",
    "\n",
    "def getgz(path):\n",
    "    raw_data = []\n",
    "    print('start to read')\n",
    "    for d in parse(path):\n",
    "        raw_data.append(d)\n",
    "        if len(raw_data) == 200000:\n",
    "            break\n",
    "    return raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import random\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def filter_review(path):\n",
    "    raw_data = getgz(path)\n",
    "    print('read done')\n",
    "    filtered = []\n",
    "    for entry in tqdm(raw_data):\n",
    "        try:\n",
    "            review = entry[\"reviewText\"]\n",
    "            rate = int(entry[\"overall\"])\n",
    "        except:\n",
    "            continue\n",
    "        if len(review.split(' ')) < 10:\n",
    "            continue\n",
    "        filtered.append(entry)\n",
    "    print('after filter: {}'.format(len(filtered)))\n",
    "    return filtered\n",
    "\n",
    "def process_entry(datas, size):\n",
    "    ratinglevel = {\n",
    "        5: \"A: very positive\",\n",
    "        4: \"B: positive\",\n",
    "        3: \"C: neutral\",\n",
    "        2: \"D: negative\",\n",
    "        1: \"E: very negative\"\n",
    "    }\n",
    "    stru_data = []\n",
    "    baseline = []\n",
    "    for i in range(len(datas)):\n",
    "        data = datas[i]\n",
    "        for entry in tqdm(data):\n",
    "            if len(stru_data) < (i+1)*size/len(datas):\n",
    "                review = entry[\"reviewText\"]\n",
    "                rating = int(entry[\"overall\"])\n",
    "                new_entry = {}\n",
    "                new_entry[\"instruction\"] = \"Given the user's review, identify the user's sentiment from the listed options. Answer using one of the options.\"\n",
    "                new_entry[\"input\"] = review\n",
    "                new_entry[\"options\"] = json.dumps(list(ratinglevel.values()))\n",
    "                new_entry[\"output\"] = ratinglevel[rating]\n",
    "                stru_data.append(new_entry)\n",
    "                rating -= 1\n",
    "                if len(datas) > 1:\n",
    "                    baseline.append([review, rating])\n",
    "\n",
    "    return stru_data, baseline\n",
    "\n",
    "def split_data(data):\n",
    "    train, val_test = train_test_split(data, test_size=0.2, random_state=seed)\n",
    "    val, test = train_test_split(val_test, test_size=0.5, random_state=seed)\n",
    "    return train, val, test\n",
    "\n",
    "def process_stru_data(cats, meta_dir, train_size, val_size, test_size):\n",
    "    trains, vals, tests = [], [], []\n",
    "    for cat in cats:\n",
    "        path = '{}/{}.json.gz'.format(meta_dir, cat)\n",
    "        data = filter_review(path)\n",
    "        print('filter done')\n",
    "        train, val, test = split_data(data)\n",
    "        trains.append(train)\n",
    "        vals.append(val)\n",
    "        tests.append(test)\n",
    "    if len(cats) == 1:\n",
    "        dir = './stru_data/sentiment_OOD'\n",
    "        if not os.path.exists(dir):\n",
    "            os.makedirs(dir)\n",
    "        stru_data, baseline = process_entry(tests, test_size)\n",
    "        dump_json(stru_data, '{}/test_{}k.json'.format(dir, len(stru_data)//1000))\n",
    "    else:\n",
    "        dir = './stru_data/sentiment_mix'\n",
    "        if not os.path.exists(dir):\n",
    "            os.makedirs(dir)\n",
    "        dir_baseline = './baseline/data/mix'\n",
    "        if not os.path.exists(dir_baseline):\n",
    "            os.makedirs(dir_baseline)\n",
    "        stru_data, baseline = process_entry(trains, train_size)\n",
    "        dump_json(stru_data, '{}/train_{}k.json'.format(dir, len(stru_data)//1000))\n",
    "        dump_json(baseline, '{}/train_{}k.json'.format(dir_baseline, len(baseline)//1000))\n",
    "        stru_data, baseline = process_entry(vals, val_size)\n",
    "        dump_json(stru_data, '{}/val_{}k.json'.format(dir, len(stru_data)//1000))\n",
    "        dump_json(baseline, '{}/val_{}k.json'.format(dir_baseline, len(baseline)//1000))\n",
    "        stru_data, baseline = process_entry(tests, test_size)\n",
    "        dump_json(stru_data, '{}/test_{}k.json'.format(dir, len(stru_data)//1000))\n",
    "        dump_json(baseline, '{}/test_{}k.json'.format(dir_baseline, len(baseline)//1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_dir = './datasets/Amazon_review/review/all_category'\n",
    "train_size, val_size, test_size = 10000, 1000, 1000\n",
    "process_stru_data(['Tools_and_Home_Improvement'], meta_dir, train_size, val_size, test_size)\n",
    "process_stru_data([\"Electronics\",\"Home_and_Kitchen\",\"Sports_and_Outdoors\"], meta_dir, train_size, val_size, test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## diverse instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diverse_instruction(path, instrs, unseen):\n",
    "    for file in os.listdir(path):\n",
    "        data = load_json(os.path.join(path, file))\n",
    "        for entry in data:\n",
    "            entry[\"instruction\"] = random.sample(instrs, k=1)[0]\n",
    "        if not os.path.exists(os.path.join('{}_di'.format(path))):\n",
    "            os.makedirs(os.path.join('{}_di'.format(path)))\n",
    "        dump_json(data, os.path.join('{}_di'.format(path), file))\n",
    "    \n",
    "        if file.startswith('test'):\n",
    "            for entry in data:\n",
    "                entry[\"instruction\"] = unseen\n",
    "            if not os.path.exists(os.path.join('{}_ui'.format(path))):\n",
    "                os.makedirs(os.path.join('{}_ui'.format(path)))\n",
    "            dump_json(data, os.path.join('{}_ui'.format(path), file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyze the user's review and determine the sentiment based on the listed options.\n"
     ]
    }
   ],
   "source": [
    "random.seed(seed)\n",
    "base_instr = \"Given the user's review, identify the user's sentiment from the listed options. Answer using one of the options.\"\n",
    "instrs = [\n",
    "    \"Assess the user's sentiment in the provided review and select the appropriate sentiment option from the list as the answer.\",\n",
    "\"Analyze the user's review and determine the sentiment based on the listed options.\",\n",
    "\"Determine the sentiment expressed by the user in her review from the provided choices, and respond by selecting one of the available options.\",\n",
    "\"Carefully assess the user's review for any strong expressions of sentiment, either positive or negative. Based on your analysis, select the most fitting sentiment option from the provided list as output.\",\n",
    "\"Analyze the user's review text and determine the overall sentiment expressed, then choose the corresponding sentiment option from the provided list (A: very positive, B: positive, C: neutral, D: negative, E: very negative) based on the identified sentiment.\"\n",
    "]\n",
    "unseen = random.sample(instrs, k=1)[0]\n",
    "instrs.remove(unseen)\n",
    "print(unseen)\n",
    "instrs.append(base_instr)\n",
    "diverse_instruction('./stru_data/sentiment_mix', instrs, unseen)\n",
    "diverse_instruction('./stru_data/sentiment_OOD', instrs, unseen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## few-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def few_shot(path):\n",
    "    test_data = load_json('{}/test_1k.json'.format(path))\n",
    "    try:\n",
    "        train_data = load_json('{}/train_10k.json'.format(path))\n",
    "    except:\n",
    "        train_data = load_json('./stru_data/sentiment_mix/train_10k.json')\n",
    "    few_shot = []\n",
    "    for index, entry in enumerate(test_data):\n",
    "        new_entry = {}\n",
    "        new_entry['instruction'] = entry['instruction']\n",
    "        new_entry['example'] = json.dumps({\n",
    "            'input': train_data[index]['input'],\n",
    "            'options': train_data[index]['options'],\n",
    "            'output': train_data[index]['output']\n",
    "        })\n",
    "        new_entry['test example'] = json.dumps({\n",
    "            'input': entry['input'],\n",
    "            'options': entry['options'],\n",
    "            'output': entry[\"output\"]\n",
    "        })\n",
    "        few_shot.append(new_entry)\n",
    "    if not os.path.exists('{}_few_shot'.format(path)):\n",
    "        os.makedirs('{}_few_shot'.format(path))\n",
    "    dump_json(few_shot, '{}_few_shot/test_1k.json'.format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot('./stru_data/sentiment_mix')\n",
    "few_shot('./stru_data/sentiment_mix_di')\n",
    "few_shot('./stru_data/sentiment_OOD')\n",
    "few_shot('./stru_data/sentiment_OOD_di')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm4rec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
