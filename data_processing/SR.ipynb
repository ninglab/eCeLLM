{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "seed = 1\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "def load_pickle(addr):\n",
    "    with open(addr, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "def dump_pickle(data, addr):\n",
    "    with open(addr, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "def load_json(addr):\n",
    "    with open(addr, 'r') as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "def dump_json(data, addr):\n",
    "    with open(addr, 'w') as f:\n",
    "        json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import gzip\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# clean text from title, description, feature and others\n",
    "def clean_text(raw_text):\n",
    "    if isinstance(raw_text, list):\n",
    "        cleaned_text = ''\n",
    "        for s in raw_text:\n",
    "            s = clean_str(s)\n",
    "            if s != '':\n",
    "                cleaned_text += ' ' + s\n",
    "\n",
    "    elif isinstance(raw_text, dict):\n",
    "        cleaned_text = clean_str(str(raw_text))\n",
    "    else:\n",
    "        cleaned_text = clean_str(raw_text)\n",
    "    return cleaned_text.strip()\n",
    "\n",
    "def clean_str(s):\n",
    "    if s == '' or len(s) >= 2000:\n",
    "        return ''\n",
    "    s = re.sub(r'[\"\\n\\r]*', '', s)\n",
    "    s = BeautifulSoup(s, 'html.parser').get_text().strip('.')\n",
    "    return s + '.'\n",
    "\n",
    "def load_ratings(file):\n",
    "    users, items, inters = set(), set(), set()\n",
    "    with open(file, 'r') as fp:\n",
    "        for line in tqdm(fp, desc='Load ratings'):\n",
    "            try:\n",
    "                item, user, rating, time = line.strip().split(',')\n",
    "                users.add(user)\n",
    "                items.add(item)\n",
    "                inters.add((user, item, float(rating), int(time)))\n",
    "            except ValueError:\n",
    "                print(line)\n",
    "    return users, items, inters\n",
    "\n",
    "def load_meta_items(file):\n",
    "    items = set()\n",
    "    with gzip.open(file, 'r') as fp:\n",
    "        for line in tqdm(fp, desc='Load metas'):\n",
    "            data = json.loads(line)\n",
    "            items.add(data['asin'])\n",
    "    return items\n",
    "\n",
    "def get_user2count(inters):\n",
    "    user2count = collections.defaultdict(int)\n",
    "    for unit in inters:\n",
    "        user2count[unit[0]] += 1\n",
    "    return user2count\n",
    "\n",
    "def get_item2count(inters):\n",
    "    item2count = collections.defaultdict(int)\n",
    "    for unit in inters:\n",
    "        item2count[unit[1]] += 1\n",
    "    return item2count\n",
    "\n",
    "def generate_candidates(unit2count, threshold):\n",
    "    cans = set()\n",
    "    for unit, count in unit2count.items():\n",
    "        if count >= threshold:\n",
    "            cans.add(unit)\n",
    "    return cans, len(unit2count) - len(cans)\n",
    "\n",
    "def filter_inters(inters, can_items=None, user_k_core_threshold=0, item_k_core_threshold=0):\n",
    "    new_inters = []\n",
    "\n",
    "    # filter by meta items\n",
    "    if can_items:\n",
    "        for unit in inters:\n",
    "            if unit[1] in can_items:\n",
    "                new_inters.append(unit)\n",
    "        inters, new_inters = new_inters, []\n",
    "        user2count = get_user2count(inters)\n",
    "        item2count = get_item2count(inters)\n",
    "\n",
    "    # filter by k-core\n",
    "    if user_k_core_threshold or item_k_core_threshold:\n",
    "        print('Filtering by {}-core:'.format(user_k_core_threshold))\n",
    "        idx = 0\n",
    "        user2count = get_user2count(inters)\n",
    "        item2count = get_item2count(inters)\n",
    "\n",
    "        while True:\n",
    "            new_user2count = collections.defaultdict(int)\n",
    "            new_item2count = collections.defaultdict(int)\n",
    "            users, n_filtered_users = generate_candidates(\n",
    "                user2count, user_k_core_threshold)\n",
    "            items, n_filtered_items = generate_candidates(\n",
    "                item2count, item_k_core_threshold)\n",
    "            if n_filtered_users == 0 and n_filtered_items == 0:\n",
    "                break\n",
    "            for unit in inters:\n",
    "                if unit[0] in users and unit[1] in items:\n",
    "                    new_inters.append(unit)\n",
    "                    new_user2count[unit[0]] += 1\n",
    "                    new_item2count[unit[1]] += 1\n",
    "            idx += 1\n",
    "            inters, new_inters = new_inters, []\n",
    "            user2count, item2count = new_user2count, new_item2count\n",
    "    return inters\n",
    "\n",
    "def make_inters_in_order(inters):\n",
    "    user2inters, new_inters = collections.defaultdict(list), list()\n",
    "    cnt = 0\n",
    "    for inter in inters:\n",
    "        user, item, rating, timestamp = inter\n",
    "        user2inters[user].append((user, item, rating, timestamp))\n",
    "    for user in user2inters:\n",
    "        user_inters = user2inters[user]\n",
    "        user_inters.sort(key=lambda d: d[3])\n",
    "        for inter in user_inters:\n",
    "            new_inters.append(inter)\n",
    "        if len(user_inters) < 5:\n",
    "            cnt += 1\n",
    "    # print('invalid number: {}'.format(cnt))\n",
    "    return new_inters\n",
    "\n",
    "def preprocess_rating(input_path, dataset, user_k, item_k):\n",
    "\n",
    "    print('Process rating data: ')\n",
    "    print('Dataset: ', dataset)\n",
    "\n",
    "    # load ratings\n",
    "    rating_file_path = os.path.join(input_path, 'rating/all_category', dataset + '.csv')\n",
    "    rating_users, rating_items, rating_inters = load_ratings(rating_file_path)\n",
    "\n",
    "    # load item IDs with meta data\n",
    "    meta_file_path = os.path.join(input_path, 'meta/all_category', f'meta_{dataset}.json.gz')\n",
    "    meta_items = load_meta_items(meta_file_path)\n",
    "\n",
    "    # 1. Filter items w/o meta data;\n",
    "    # 2. K-core filtering;\n",
    "    # print('The number of raw inters: ', len(rating_inters))\n",
    "    rating_inters = filter_inters(rating_inters, can_items=meta_items, user_k_core_threshold=user_k, item_k_core_threshold=item_k)\n",
    "\n",
    "    # sort interactions chronologically for each user\n",
    "    rating_inters = make_inters_in_order(rating_inters)\n",
    "\n",
    "    # return: list of (user_ID, item_ID, rating, timestamp)\n",
    "    return rating_inters\n",
    "\n",
    "def load_inters(path, dataset):\n",
    "    # load interactions from raw rating file\n",
    "    rating_inters = preprocess_rating(path, dataset, user_k=5, item_k=5)\n",
    "    itemcnt = get_item2count(rating_inters)\n",
    "    return rating_inters, itemcnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_metadata(input_path, dataset, itemcnt):\n",
    "    path14 = os.path.join(input_path, 'meta/all_category_2014', f'meta_{dataset}.json.gz')\n",
    "    path18 = os.path.join(input_path, 'meta/all_category', f'meta_{dataset}.json.gz')\n",
    "\n",
    "    metadata18 = {}\n",
    "    g_file18 = gzip.GzipFile(path18)\n",
    "    for line in g_file18.readlines():\n",
    "        dic = json.loads(line)\n",
    "        id = dic['asin']\n",
    "        # filter the items that in interaction\n",
    "        if id in itemcnt.keys():\n",
    "            metadata18[id] = dic\n",
    "    g_file18.close()\n",
    "\n",
    "    if path14 == '':\n",
    "        return {}, metadata18\n",
    "\n",
    "    metadata14 = {}\n",
    "    g_file14 = gzip.GzipFile(path14)\n",
    "    for line in g_file14.readlines():\n",
    "        dic = eval(line)\n",
    "        # filter the items that also in interaction\n",
    "        if dic['asin'] in itemcnt.keys():\n",
    "            metadata14[dic['asin']] = dic\n",
    "    g_file14.close()\n",
    "    \n",
    "    return metadata14, metadata18\n",
    "\n",
    "def generate_text(input_path, dataset, contents):\n",
    "    content = 'title'\n",
    "    rating_inters, items = load_inters(input_path, dataset)\n",
    "    print('Process text data: ')\n",
    "    item_text_dict = {}\n",
    "    already_items = set()\n",
    "    metadata14, metadata18 = load_metadata(input_path, dataset, items)\n",
    "\n",
    "    for id in metadata18:\n",
    "        item18 = metadata18[id]\n",
    "        item14 = {}\n",
    "        if id in metadata14:\n",
    "            item14 = metadata14[id]\n",
    "        if id in items and id not in already_items:\n",
    "            already_items.add(id)\n",
    "            text = ''\n",
    "            # merge the 2018 metainfo with 2014, and generate text for item id\n",
    "            for content in contents:\n",
    "                con18, con14 = '', ''\n",
    "                if content in item18:\n",
    "                    con18 = item18[content]\n",
    "                if content in item14:\n",
    "                    con14 = item14[content]\n",
    "                if len(con18) == 0 and len(con14) != 0:\n",
    "                    con_value = con14\n",
    "                else:\n",
    "                    con_value = con18\n",
    "                if content == 'category' and len(con_value) > 2:\n",
    "                    con_value = con_value[:2]\n",
    "                text += clean_text(con_value) + ' '\n",
    "            item_text_dict[id] = text.strip(' ')\n",
    "    return item_text_dict, rating_inters\n",
    "\n",
    "def process_history(input_path, dataset, inter_threshold):\n",
    "    item_text_dict, rating_inters = generate_text(input_path, dataset, ['title', 'category', 'brand'])\n",
    "    user_inters = {}\n",
    "    inters = []\n",
    "    cntlen = 0\n",
    "    for inter in rating_inters:\n",
    "        user = inter[0]\n",
    "        item = inter[1]\n",
    "        if user not in user_inters:\n",
    "            user_inters[user] = []\n",
    "        if len(user_inters[user]) < inter_threshold:\n",
    "            user_inters[user].append(item_text_dict[item])\n",
    "        cntlen += len(item_text_dict[item].split(' '))\n",
    "    for user in user_inters:\n",
    "        inters.append(user_inters[user])\n",
    "    print('average text length: {}'.format(cntlen/len(rating_inters)))\n",
    "    return inters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordinal(i):\n",
    "    if i > 20:\n",
    "        if i % 10 == 1:\n",
    "            return str(i) + 'st'\n",
    "        if i % 10 == 2:\n",
    "            return str(i) + 'nd'\n",
    "        if i % 10 == 3:\n",
    "            return str(i) + 'rd'\n",
    "        return str(i) + 'th'\n",
    "    if i == 1:\n",
    "        return str(i) + 'st'\n",
    "    if i == 2:\n",
    "        return str(i) + 'nd'\n",
    "    if i == 3:\n",
    "        return str(i) + 'rd'\n",
    "    return str(i) + 'th'\n",
    "\n",
    "def cutitem(item, word_threshold=25):\n",
    "    words = item.split(' ')\n",
    "    if len(words) > word_threshold:\n",
    "        return ' '.join(words[:word_threshold]).strip('.') + '...'\n",
    "    return item\n",
    "\n",
    "def allitems(datas):\n",
    "    items = set()\n",
    "    for data in datas:\n",
    "        for entry in data:\n",
    "            for item in entry:\n",
    "                items.add(item)\n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_candidates(entry, cand_potential, num_cand, mode):\n",
    "    candidates = random.sample(cand_potential, k=num_cand-1)\n",
    "    candidates.append(entry[mode-3])\n",
    "    random.shuffle(candidates)\n",
    "    return candidates\n",
    "\n",
    "def process_entry(entry, base_instr, cand_potential, num_cand, mode, word_threshold=25):\n",
    "    candidates = process_candidates(entry, cand_potential, num_cand, mode)\n",
    "    target_idx = candidates.index(entry[mode-3])\n",
    "    new_entry = {}\n",
    "    new_entry[\"instruction\"] = base_instr\n",
    "    new_entry[\"input\"] = str([ordinal(i+1) + ': ' + cutitem(entry[i], word_threshold) for i in range(len(entry)+mode-3)])\n",
    "    new_entry[\"options\"] = str([chr(65+i) + ': ' + cutitem(candidates[i], word_threshold) for i in range(len(candidates))])\n",
    "    new_entry[\"output\"] = chr(65+target_idx)\n",
    "    return new_entry, candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_stru_data(dir, data_dict, ood=False):\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "    if not ood:\n",
    "        dump_json(data_dict[0], '{}/train_{}k.json'.format(dir, len(data_dict[0])//1000))\n",
    "        dump_json(data_dict[1], '{}/val_{}k.json'.format(dir, len(data_dict[1])//1000))\n",
    "    dump_json(data_dict[2], '{}/test_{}k.json'.format(dir, len(data_dict[2])//1000))\n",
    "\n",
    "def process_stru_data(data, base_instr, cand_pool, cat, train_size=10000, test_size=1000, num_cand=20, ood=False, isbaseline=False, word_threshold=25):\n",
    "    stru_dict = {0: [], 1: [], 2: []}\n",
    "    raw_data = {0: [], 1: [], 2: []}\n",
    "    if ood:\n",
    "        train_size = test_size\n",
    "    for entry in tqdm(data):\n",
    "        if len(stru_dict[0]) == train_size:\n",
    "            break\n",
    "        cand_potential = list(cand_pool - set([entry[-3], entry[-2], entry[-1]]))\n",
    "        for mode in [0,1,2]:\n",
    "            if mode != 0 and len(stru_dict[2]) == test_size:\n",
    "                continue\n",
    "            new_entry, candidates = process_entry(entry, base_instr, cand_potential, num_cand, mode, word_threshold=word_threshold)\n",
    "            stru_dict[mode].append(new_entry)\n",
    "            raw_data[mode].append([[entry[i] for i in range(len(entry)+mode-2)], candidates])\n",
    "    print(stru_dict[2][0]['options'])\n",
    "    return stru_dict, raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(cats, base_instr, train_size=10000, test_size=1000, ood=False):\n",
    "    path = './datasets/Amazon_review'\n",
    "    datas = {}\n",
    "    inter_threshold = 50\n",
    "    word_threshold = 25\n",
    "    for cat in cats:\n",
    "        inter_path = './raw_data/raw_inters/{}.pickle'.format(cat)\n",
    "        if not os.path.exists(inter_path):\n",
    "            inters = process_history(path, cat, inter_threshold)\n",
    "            dump_pickle(inters, inter_path)\n",
    "        else:\n",
    "            inters = load_pickle(inter_path)\n",
    "        random.shuffle(inters)\n",
    "        datas[cat] = inters\n",
    "    cand_pool = allitems([datas[i] for i in datas])\n",
    "    for cat in datas:\n",
    "        if ood:\n",
    "            stru_dict, raw_data = process_stru_data(datas[cat], base_instr, cand_pool, cat, train_size, test_size, ood=True, word_threshold=word_threshold)\n",
    "            dump_stru_data('./stru_data/sequential_rec_OOD', stru_dict, ood=True)\n",
    "            dump_stru_data('./raw_data/sequential_rec_OOD', raw_data, ood=True)\n",
    "        else:\n",
    "            stru_dict, raw_data = process_stru_data(datas[cat], base_instr, cand_pool, cat, train_size, test_size, isbaseline=True, word_threshold=word_threshold)\n",
    "            dump_stru_data('./stru_data/in_cat/sequential_rec_{}'.format(cat), stru_dict)\n",
    "            dump_stru_data('./raw_data/sequential_rec_{}'.format(cat), raw_data)\n",
    "\n",
    "def mix_data(dir, dump_dir, cats, train_size=10000, test_size=1000):\n",
    "    trains, vals, tests = [],[],[]\n",
    "    for idx, cat in enumerate(cats):\n",
    "        if idx == len(cats)-1:\n",
    "            trains += load_json('{}_{}/train_10k.json'.format(dir, cat))[:(train_size-len(trains))]\n",
    "            vals += load_json('{}_{}/val_1k.json'.format(dir, cat))[:test_size-len(vals)]\n",
    "            tests += load_json('{}_{}/test_1k.json'.format(dir, cat))[:test_size-len(tests)]\n",
    "        else:\n",
    "            trains += load_json('{}_{}/train_10k.json'.format(dir, cat))[:train_size//len(cats)]\n",
    "            vals += load_json('{}_{}/val_1k.json'.format(dir, cat))[:test_size//len(cats)]\n",
    "            tests += load_json('{}_{}/test_1k.json'.format(dir, cat))[:test_size//len(cats)]\n",
    "    dump_json(trains, '{}/train_{}k.json'.format(dump_dir, len(trains)//1000))\n",
    "    dump_json(vals, '{}/val_{}k.json'.format(dump_dir, len(vals)//1000))\n",
    "    dump_json(tests, '{}/test_{}k.json'.format(dump_dir, len(tests)//1000))\n",
    "\n",
    "def process_mix_data(cats, base_instr, train_size=10000, test_size=1000):\n",
    "    dir = './stru_data/sequential_rec_mix'\n",
    "    raw_mix_dir = './raw_data/sequential_rec_mix'\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "        preprocess(cats, base_instr, train_size, test_size)\n",
    "    if not os.path.exists(raw_mix_dir):\n",
    "        os.makedirs(raw_mix_dir)\n",
    "    mix_data('./stru_data/in_cat/sequential_rec', dir, cats, train_size=10000, test_size=1000)\n",
    "    mix_data('./raw_data/sequential_rec', raw_mix_dir, cats, train_size=10000, test_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1000/219152 [00:03<13:43, 265.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A: IIT 48795 Glow-In-The Dark Rope. Tools & Home Improvement. Hardware. IIT.', 'B: 8 Kwikset Emergency Keys for Interior Door Locksets (8). Tools & Home Improvement. Hardware. Kwikset.', 'C: Krylon K05125000 ColorMaster Paint & Primer Brushed Metallic Spray Paint, Caramel Latte, 11 Ounce. Tools & Home Improvement. Paint, Wall Treatments & Supplies. Krylon.', 'D: Hitachi UC18YSL3 18V Lithium-Ion Battery Rapid Charger w/ USB Port. Tools & Home Improvement. Power & Hand Tools. Hitachi.', 'E: Dragway Tools Rubber Sandblasting Gloves for Model 60, 90, 110, 260 Sandblast Cabinets. Tools & Home Improvement. Safety & Security. Dragway Tools.', 'F: UltraFire 1000 Lumens CREE XM-L T6 LED Flashlight Torch+2x18650 Battery+Charger. Tools & Home Improvement. Safety & Security. ULTRAFIRE.', 'G: Full Overlay Blum 110 deg Soft-Close BLUMotion Clip Top Frameless Hinges, Pair. Tools & Home Improvement. Hardware. Blum.', 'H: Industrial Air Contractor CTA5090412 4-Gallon Grade Direct Drive Pontoon Air Compressor with Honda Engine. Tools & Home Improvement. Power & Hand Tools. Industrial Air Contractor.', 'I: Bi-fold Door, Louver/panel Style 1x32x80. Tools & Home Improvement. Building Supplies. Kimberly Bay .', 'J: Westek MLC12BC-4 Indoor Plug-In Corded Motion Activated Light Control.  Westek.', 'K: Kichler 340014, Umber Etched Glass Bowl, Umber Etched. Tools & Home Improvement. Lighting & Ceiling Fans. KICHLER.', 'L: First Alert P910  10-Year Maximum Protection Photoelectric Smoke and Fire Detector, White. Tools & Home Improvement. Safety & Security. First Alert.', 'M: TerraLUX TLE-5 MiniStar2 1-Watt LED Replacement Bulb Kit for 2AA Mini Maglites. Tools & Home Improvement. Light Bulbs. TerraLUX.', 'N: Evolution Power Tools 14BLADEWD 14-Inch Wood Cutting Blade with 1-Inch Arbor. Tools & Home Improvement. Power & Hand Tools. Evolution Power Tools.', 'O: uxcell 5PCS 100Kg 220Lbs Capacity Pull Action Latch Type Toggle Clamp 4001.  uxcell.', 'P: Edge Eyewear SK-XL112 Kazbek XL Safety Glasses, Black with Yellow Lens. Tools & Home Improvement. Safety & Security. Edge Eyewear.', 'Q: Command Broom Holder Wall Mount, White with Grey Band, Decorate Damage Free, Strong and Versatile, 1 gripper.  Command.', 'R: Hometown Evolution, Inc. Box of 25 G50 Clear 2 Inch 7 Watt C7 Base Replacement Bulbs. Tools & Home Improvement. Light Bulbs. TooTa.', 'S: T-Lock TM 1/16\" (2mm) 250 Clips\" PERFECT LEVEL MASTER TM Professional\" Anti lippage\" Tile leveling system - (spacers only), Red wedges not included and sold...', 'T: JACKYLED Extension Hanging Lantern Cord Cable UL 12Ft 360W with E26 E27 Socket On/Off Button + Hooks + 2-Prong AC Power Plugs Pendant Lighting for...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 10000/695321 [07:17<8:19:24, 22.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A: Case Logic TBC-302BLACK Black Ultra-Compact Camera Case With Storage. Electronics. Camera & Photo. Case Logic.', 'B: DreamCatcher~ DreamCatcher Feathers~ Approx 4.5\" Diameter 12\" long. Home & Kitchen. Home Dcor. PennyLaneGifts.com.', 'C: LQM 671731-001 MO06 MO09 Laptop Battery for HP Pavilion DV4-5000 DV6-7000 DV7-7000 Envy DV4-5200 Compatible 671567-321 H2L55AA (MO06). Electronics. Computers & Accessories. LQM.', 'D: Crystal Allies Natural Himalayan Salt Lamp and 2 Piece Cylinder Tea Candle Holder Combo with Dimmable Cord and Bulb. Home & Kitchen. Home Dcor. Crystal...', 'E: Personalized Mailman Christmas Holiday Gift Expertly Handwritten Ornament. Home & Kitchen. Home Dcor. Ornaments.', 'F: Chillz 3-in-1 Wine Bottle Cooler Stick - Best Barware Tool - Stainless Steel Chiller Cooling Rod - Air Aerator and Pourer (1pack). Home & Kitchen...', 'G: HiRO H50320 Dual Band Wireless 802.11ac AC1200 11ac WiFi 2T2R 867Mbps Low Profile PCIe PCI Express PCI-E x1 Adapter 2x 2dBi Dipole Antenna Windows 10...', 'H: JJC GSPEM1 Optical Glass Screen Protector for Olympus OM-D E-M1 E-M10 Pen E-P5 Digital Camera (Clear). Electronics. Camera & Photo. JJC.', 'I: HUJI Adjustable Natural Finish Under Cabinet Wood Wine Glass Rack Storage (2 Racks, Wood). Home & Kitchen. Kitchen & Dining. Huji.', 'J: Look Cycle Keo Cleat Cover. Sports & Outdoors. Outdoor Recreation. Look.', 'K: Olympus V6200660U000 Li-92 Rechargeable Battery (Silver). Electronics. Camera & Photo. Olympus.', \"L: Olivia's Heartland Deluxe Crème Burlap Tree Skirt. Home & Kitchen. Seasonal Dcor. Olivia's Heartland.\", 'M: CyclingDeal Bike Front Baby Seat Carrier with Handrail and Helmet. Sports & Outdoors. Outdoor Recreation. CyclingDeal.', 'N: Boogie Board Replacement Stylus Sync 9.7 (SY0910001). Electronics. Computers & Accessories. Boogie Board.', 'O: Nikon Binoc-U-Mount Universal Tripod Adapter. Electronics. Camera & Photo. Nikon.', 'P: Dr.Fish Saltwater Fishing Lure Trolling Squid Offshore Bait Teaser 6\" Built-in LED Light Mahi Tuna Marlin Sails Wahoo. Sports & Outdoors. Sports & Fitness. Dr.Fish.', 'Q: Sougayilang 100pcs Fishing Leader Rigging Trace Lure Snaps Swivel Steel Wire Spinner Tackle Lines Rig Test 28.6lbs. Sports & Outdoors. Sports & Fitness. Sougayilang.', 'R: Set of 2 Heart Shaped Curtain Tie Backs. Home & Kitchen. Home Dcor. GetSet2Save.', 'S: Pyrex Storage Deluxe 3-2/3-Cup Oval Dish, Clear with Blue Lid. Home & Kitchen. Kitchen & Dining. Pyrex.', 'T: Generic Touch Stylus Pen for iPhone 5/4s/4/3GS, iPad 3/2, iPod Touch, Samsung, HTC, 12-Pieces - Non-Retail Packaging - Multi. Electronics. Computers & Accessories. Yesker.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 10000/731913 [06:52<8:16:41, 24.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A: Vacu Vin Food Saver for Tea and Nuts .65 liter. Home & Kitchen. Kitchen & Dining. Vacu Vin.', 'B: Kanex K166-1013 MultiSync Aluminum Bluetooth Full Size Keyboard w/Numeric keypad-Compatible w/iPhone/iPad/MacBook/Mac. Electronics. Computers & Accessories. Kanex.', 'C: OAproda 2 Pack EN-EL12 Battery and Ultra Slim USB Charger for Nikon KeyMission 360, KeyMission 170, Coolpix AW100, AW110, AW100s, AW120, AW130, S9500, S9300, S9200,...', 'D: Teyeleec Qanliiy 10-100x21 Pocket-size Mini Hd Monocular Telescope Objective Lens 21mm 66m/8000m. Electronics. Camera & Photo. TRADERPLUS.', 'E: Noctua NF-S12B FLX 120 mm 3 Speed Setting Beveled Blade Tips Design SSO Bearing Fan SCD 2 - Retail. Electronics. Computers & Accessories. Axpertec Inc.', 'F: Adorama 20-Inch Standard Cable Release with Screw Lock. Electronics. Camera & Photo. Adorama.', 'G: Eathtek Replacement CPU Cooling Cooler Fan for Dell Inspiron 17R N7010 series, Compatible with part numbers 0RKVVP RKVVP MF60100V1-C010-G99 (Note: Only fit for N7010 series...', 'H: MERRITHEW Eco Yoga Mat (TPE) (Maroon/Charcoal), 0.125 inch / 3 mm. Sports & Outdoors. Sports & Fitness. Merrithew.', 'I: Home Styles Bordeaux King/California King Headboard. Home & Kitchen. Furniture. Home Styles.', 'J: Miles Kimball Flannel Sheet Sets. Home & Kitchen. Bedding. Miles Kimball.', 'K: Butter Dish with Lid White Fine Porcelain. Home & Kitchen. Kitchen & Dining. Chefcaptain.', 'L: Polar H6 Heart Rate Sensor. Sports & Outdoors. Sports & Fitness. Polar.', 'M: Insten 4X Hot Shoe cap cover Compatible with CANON 40D 50D 400D 450D 1000D. Electronics. Camera & Photo. eForCity.', 'N: Maximal Power 67mm Lens Filter Kit Includes Circular Polarizer, UV and Star Lens Filter Kit for 67mm Camera Lens (Black). Electronics. Camera & Photo. MaximalPower.', 'O: U32 Shadow™ 256GB External USB 3.0 Portable Solid State Drive SSD. Electronics. Computers & Accessories. Oyen Digital.', 'P: Generic 5.0 Megapixel USB PC Webcam Camera for PC Laptop Noteboo. Electronics. Computers & Accessories. SANOXY.', 'Q: Broil King PCG-10 Professional Portable Nonstick Griddle. Home & Kitchen. Kitchen & Dining. Broil King.', 'R: LEE PRECISION 7.62X39R Pacesetter Dies. Sports & Outdoors. Sports & Fitness. LEE PRECISION.', 'S: Generic 14.8V 5200mAh Lapotp Battery For Sager NP8150 NP8130 Clevo P150HM P151HM P150HMBAT-8 Color Black. Electronics. Computers & Accessories. Generic.', 'T: CAT EYE - Rapid X3 USB Rechargeable LED Bike Safety Light. Sports & Outdoors. Outdoor Recreation. CAT EYE.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 10000/300007 [06:46<3:16:40, 24.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A: Spring Creek Horse Sculpted Mug by Chris Cummings. Home & Kitchen. Kitchen & Dining. Wild Wings.', 'B: Bentology Lunch Bag and Box Set - Includes Insulated Bag with Handle, Bento Box, 5 Containers and Ice Pack (Kitty). Home & Kitchen. Kitchen &...', 'C: Black Mountain Products Yoga and Exercise Mat, 1/2 x 73 1/2 x 24 1/2-Inch. Sports & Outdoors. Sports & Fitness. Black Mountain.', 'D: SWFA SS 10x42 Tactical Riflescope MOA-Quad Reticle 1/4 MOA Adjustments Rear Focus SS10X42MOA. Sports & Outdoors. Sports & Fitness. SWFA.', 'E: Krismile New Romantic Personalised Wooden Mr & Mrs Love Wedding Table Decoration Favour (white). Home & Kitchen. Wall Art. Krismile.', 'F: Lorex QLR464 4-Channel PCI DVR Card with 4 Indoor/Outdoor Night Vision Security Camera (Black). Electronics. Camera & Photo. Lorex.', 'G: Household Essentials 1842 Three-Shelf Natural Canvas Hanging Sweater Organizer. Home & Kitchen. Storage & Organization. Household Essentials.', 'H: SET OF TWO (2) - 6-Inch Serving Ladle, Gravy Ladle, Sauce Ladle, Kitchen Ladle, High-Polished Chrome, Crown & Claridge Sytle. Home & Kitchen. Kitchen &...', 'I: Cable Clamp - 100 pack (5/16 inch, Black). Electronics. Accessories & Supplies. Secure Cable Ties.', 'J: Minolta Dimage 5 3MP Digital Camera w/ 7x Optical Zoom. Electronics. Camera & Photo. Konica-Minolta.', 'K: Rii i8 (10038-AM) Mini 2.4GHz Wireless Touchpad Keyboard with Mouse, Black. Electronics. Computers & Accessories. Rii.', 'L: Panasonic DMC-ZS40S Digital Camera with 3.0-Inch LCD (Silver) (Certified Refurbished). Electronics. Camera & Photo. Panasonic.', 'M: Joy Mangano My Little Steamer and Go Mini Shine Like a Gem Set with Glam Bag - Purple Amethyst. Home & Kitchen. Vacuums & Floor...', 'N: LimoStudio 800W Photography Photo Portrait Studio Umbrella Triple Continuous Lighting Kit - 2 x White Umbrella Lighitng, 1 x Table Top Mini Lighting Kit, AGG1210...', 'O: Winn Dritac Golf Grips Dritac. Sports & Outdoors. Sports & Fitness. Winn.', 'P: SWFA SS 12x42 Tactical 30mm Riflescope. Sports & Outdoors. Sports & Fitness. SWFA SS.', 'Q: Disney Princess Birthday Party Tiara Wearable Accessory Supply (1 Piece), Pink/Silver, 5\" x 5 1/2\". Home & Kitchen. Event & Party Supplies. American Greetings.', 'R: Beer Cap Trap Pennsylvania Beer Cap Map Wall Art, Tan. Home & Kitchen. Kitchen & Dining. Beer Cap Trap.', 'S: Nikon Pre-Moistened Lens Cloths Wipes 50 Ct. Electronics. Accessories & Supplies. Nikon.', 'T: iecool Spherical Dual Lenses Anti-Fog Professional Ski Goggles. Sports & Outdoors. Outdoor Recreation. iecool.']\n"
     ]
    }
   ],
   "source": [
    "seed = 1\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "base_instr = \"Given the products the user has purchased in history, rank the items in the listed options and output the item that the user is most likely to purchase next. Answer from one of the options.\"\n",
    "preprocess(['Tools_and_Home_Improvement'], base_instr, ood=True)\n",
    "process_mix_data([\"Electronics\",\"Home_and_Kitchen\",\"Sports_and_Outdoors\"], base_instr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## diverse instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diverse_instruction(path, instrs, unseen):\n",
    "    for file in os.listdir(path):\n",
    "        data = load_json(os.path.join(path, file))\n",
    "        for entry in data:\n",
    "            entry[\"instruction\"] = random.sample(instrs, k=1)[0]\n",
    "        if not os.path.exists(os.path.join('{}_di'.format(path))):\n",
    "            os.makedirs(os.path.join('{}_di'.format(path)))\n",
    "        dump_json(data, os.path.join('{}_di'.format(path), file))\n",
    "    \n",
    "        if file.startswith('test'):\n",
    "            for entry in data:\n",
    "                entry[\"instruction\"] = unseen\n",
    "            if not os.path.exists(os.path.join('{}_ui'.format(path))):\n",
    "                os.makedirs(os.path.join('{}_ui'.format(path)))\n",
    "            dump_json(data, os.path.join('{}_ui'.format(path), file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate the user's intent based on the user's purchase history, and predict the next product that the user is most likely to purchase from the given options.\n"
     ]
    }
   ],
   "source": [
    "random.seed(seed)\n",
    "base_instr = \"Given the products the user has purchased in history, rank the items in the listed options and output the item that the user is most likely to purchase next. Answer from one of the options.\"\n",
    "instrs = [\n",
    "\"Based on the user's historical purchases, rank the items in options and predict the next product of the user's interest from the provided options.\",\n",
    "\"Estimate the user's intent based on the user's purchase history, and predict the next product that the user is most likely to purchase from the given options.\",\n",
    "\"Rank the items in options and predict the user's next purchase from the listed options by analyzing her historical purchases.\",\n",
    "\"The user's purchase history implies her preferences. Rank the items in the options based on the user's preferences. Output the item that the user is most likely to purchase next from the options.\",\n",
    "\"Rank items in listed options based on the user's purchase history to determine the item that the user is most likely to purchase next. Output the item with the highest likelihood of being the next purchase.\"\n",
    "]\n",
    "unseen = random.sample(instrs, k=1)[0]\n",
    "instrs.remove(unseen)\n",
    "print(unseen)\n",
    "instrs.append(base_instr)\n",
    "diverse_instruction('./stru_data/sequential_rec_mix', instrs, unseen)\n",
    "diverse_instruction('./stru_data/sequential_rec_OOD', instrs, unseen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## few-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def few_shot(path):\n",
    "    test_data = load_json('{}/test_1k.json'.format(path))\n",
    "    try:\n",
    "        train_data = load_json('{}/train_10k.json'.format(path))\n",
    "    except:\n",
    "        train_data = load_json('./stru_data/sequential_rec_mix/train_10k.json')\n",
    "    few_shot = []\n",
    "    for index, entry in enumerate(test_data):\n",
    "        new_entry = {}\n",
    "        new_entry['instruction'] = entry['instruction']\n",
    "        new_entry['example'] = json.dumps({\n",
    "            'input': train_data[index]['input'],\n",
    "            'options': train_data[index]['options'],\n",
    "            'output': train_data[index]['output']\n",
    "        })\n",
    "        new_entry['test example'] = json.dumps({\n",
    "            'input': entry['input'],\n",
    "            'options': entry['options'],\n",
    "            'output': entry[\"output\"]\n",
    "        })\n",
    "        few_shot.append(new_entry)\n",
    "    if not os.path.exists('{}_few_shot'.format(path)):\n",
    "        os.makedirs('{}_few_shot'.format(path))\n",
    "    dump_json(few_shot, '{}_few_shot/test_1k.json'.format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot('./stru_data/sequential_rec_mix')\n",
    "few_shot('./stru_data/sequential_rec_mix_di')\n",
    "few_shot('./stru_data/sequential_rec_OOD')\n",
    "few_shot('./stru_data/sequential_rec_OOD_di')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm4rec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
