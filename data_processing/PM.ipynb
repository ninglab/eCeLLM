{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "seed = 1\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def load_pickle(addr):\n",
    "    with open(addr, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "def dump_pickle(data, addr):\n",
    "    with open(addr, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "def load_json(addr):\n",
    "    with open(addr, 'r') as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "def dump_json(data, addr):\n",
    "    with open(addr, 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "def load_df(addr):\n",
    "    with open(addr, 'r') as f:\n",
    "        return pd.read_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def read_df(path):\n",
    "    amazon = load_df(os.path.join(path, 'Amazon.csv'))\n",
    "    google = load_df(os.path.join(path, 'GoogleProducts.csv'))\n",
    "    matched = load_df(os.path.join(path, 'Amzon_GoogleProducts_perfectMapping.csv'))\n",
    "    dfmerge_a = matched.merge(amazon,how='inner',left_on='idAmazon',right_on='id').drop('id', axis=1)\n",
    "    dfmerge = dfmerge_a.merge(google,left_on='idGoogleBase',right_on='id',suffixes=('_a','_g')).drop('id', axis=1)\n",
    "    return dfmerge, amazon, google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def process_desc(text):\n",
    "    if len(str(text).split(' ')) > 50:\n",
    "        return ' '.join(str(text).split(' ')[:50]).strip('.') + '...'\n",
    "    return text\n",
    "\n",
    "def process_positives(df):\n",
    "    stru_data, product_pair = [], set()\n",
    "    for index, entry in df.iterrows():\n",
    "        prod_a = {\n",
    "            'title': entry['title'],\n",
    "            'description': process_desc(entry['description_a']),\n",
    "            'manufacturer': str(entry['manufacturer_a']),\n",
    "            'price': str(entry['price_a'])\n",
    "        }\n",
    "        prod_g = {\n",
    "            'title': entry['name'],\n",
    "            'description': process_desc(entry['description_g']),\n",
    "            'manufacturer': str(entry['manufacturer_g']),\n",
    "            'price': str(entry['price_g'])\n",
    "        }\n",
    "        if (str(prod_a), str(prod_g)) in product_pair or (str(prod_g), str(prod_a)) in product_pair:\n",
    "            continue\n",
    "        product_pair.add((str(prod_a), str(prod_g)))\n",
    "        product_pair.add((str(prod_g), str(prod_a)))\n",
    "\n",
    "        new_entry = {}\n",
    "        new_entry[\"instruction\"] = \"Given the title, description, manufacturer, and price of two products, identify if they are the same product. Only output yes or no.\"\n",
    "        new_entry[\"input\"] = json.dumps({'product 1': prod_a, 'product 2': prod_g})\n",
    "        new_entry[\"output\"] = 'yes'\n",
    "        stru_data.append(new_entry)\n",
    "\n",
    "    return stru_data, product_pair\n",
    "    \n",
    "def process_negatives(size, product_pair, amazon, google):\n",
    "    stru_data = []\n",
    "    amazon = amazon.sample(frac=1, random_state=seed)\n",
    "    google = google.sample(frac=1, random_state=seed)\n",
    "    for index, prod_a in amazon.iterrows():\n",
    "        if len(stru_data) == size:\n",
    "            break\n",
    "        prod_g = google.iloc[index]\n",
    "        prod_a = {'title': prod_a['title'],\n",
    "                  'description': process_desc(prod_a['description']),\n",
    "                  'manufacturer': str(prod_a['manufacturer']),\n",
    "                  'price': str(prod_a['price'])}\n",
    "        prod_g = {'title': prod_g['name'],\n",
    "                  'description': process_desc(prod_g['description']),\n",
    "                  'manufacturer': str(prod_g['manufacturer']),\n",
    "                  'price': str(prod_g['price'])}\n",
    "        if (str(prod_a), str(prod_g)) not in product_pair and (str(prod_g), str(prod_a)) not in product_pair:\n",
    "            new_entry = {}\n",
    "            new_entry[\"instruction\"] = \"Given the title, description, manufacturer, and price of two products, identify if they are the same product. Only output yes or no.\"\n",
    "            new_entry[\"input\"] = json.dumps({'product 1': prod_a, 'product 2': prod_g})\n",
    "            new_entry[\"output\"] = 'no'\n",
    "            stru_data.append(new_entry)\n",
    "            product_pair.add((str(prod_a), str(prod_g)))\n",
    "            product_pair.add((str(prod_g), str(prod_a)))\n",
    "    return stru_data\n",
    "\n",
    "def process_matching(path):\n",
    "    df, amazon, google = read_df(path)\n",
    "    pos, pairs = process_positives(df)\n",
    "    neg = process_negatives(len(pos), pairs, amazon, google)\n",
    "    stru_data = [*pos, *neg]\n",
    "    train, test_val = train_test_split(stru_data, test_size=0.2, random_state=seed)\n",
    "    val, test = train_test_split(test_val, test_size=0.5, random_state=seed)\n",
    "    print(test[0]['input'])\n",
    "    print(len(train))\n",
    "    dump_json(train, './stru_data/matching/train_10k.json')\n",
    "    dump_json(val, './stru_data/matching/val_1k.json')\n",
    "    dump_json(test, './stru_data/matching/test_1k.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"product 1\": {\"title\": \"weekly reader preparing for kindergarten\", \"description\": NaN, \"manufacturer\": \"fogware publishing\", \"price\": \"19.99\"}, \"product 2\": {\"title\": \"mcafee inc total protection 2007 3-user\", \"description\": \"mcafee\\ufffd total protection peace of mind for your entire family today the variety of threats to your pc fi les and online identity is bewildering.viruses spyware hackers spam and emailscams online predators identitythie\", \"manufacturer\": \"nan\", \"price\": \"92.51\"}}\n",
      "2022\n"
     ]
    }
   ],
   "source": [
    "path = './datasets/Amazon_Google_products'\n",
    "process_matching(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## diverse instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diverse_instruction(path, instrs, unseen):\n",
    "    for file in os.listdir(path):\n",
    "        data = load_json(os.path.join(path, file))\n",
    "        for entry in data:\n",
    "            entry[\"instruction\"] = random.sample(instrs, k=1)[0]\n",
    "        if not os.path.exists(os.path.join('{}_di'.format(path))):\n",
    "            os.makedirs(os.path.join('{}_di'.format(path)))\n",
    "        dump_json(data, os.path.join('{}_di'.format(path), file))\n",
    "    \n",
    "        if file.startswith('test'):\n",
    "            for entry in data:\n",
    "                entry[\"instruction\"] = unseen\n",
    "            if not os.path.exists(os.path.join('{}_ui'.format(path))):\n",
    "                os.makedirs(os.path.join('{}_ui'.format(path)))\n",
    "            dump_json(data, os.path.join('{}_ui'.format(path), file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determine whether the two products are the same by comparing their title, description, manufacturer, and price, and provide a simple yes or no answer as the output.\n"
     ]
    }
   ],
   "source": [
    "random.seed(seed)\n",
    "base_instr = \"Given the title, description, manufacturer, and price of two products, identify if they are the same product. Only output yes or no.\"\n",
    "instrs = [\n",
    "\"Analyze the title, description, manufacturer, and price between the two products below and generate an output of yes if the two products are the same, otherwise respond with no.\",\n",
    "\"Determine whether the two products are the same by comparing their title, description, manufacturer, and price, and provide a simple yes or no answer as the output.\",\n",
    "\"Check the details of the two products to see if they refer to the same product. Output only yes or no.\",\n",
    "\"Based on the product information, predict if the two products are identical or not. Output yes if they are identical or no otherwise.\",\n",
    "\"Compare the details of two given products to determine if they are identical. Output yes if they are identical or no otherwise.\"\n",
    "]\n",
    "unseen = random.sample(instrs, k=1)[0]\n",
    "instrs.remove(unseen)\n",
    "print(unseen)\n",
    "instrs.append(base_instr)\n",
    "diverse_instruction('./stru_data/matching', instrs, unseen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## few-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = load_json('./stru_data/matching/test_1k.json')\n",
    "train_data = load_json('./stru_data/matching/train_10k.json')\n",
    "few_shot = []\n",
    "for index, entry in enumerate(test_data):\n",
    "    new_entry = {}\n",
    "    new_entry['instruction'] = base_instr\n",
    "    new_entry['example'] = json.dumps({\n",
    "        'input': train_data[index]['input'],\n",
    "        'output': train_data[index]['output']\n",
    "    })\n",
    "    new_entry['test example'] = json.dumps({\n",
    "        'input': entry['input'],\n",
    "        'output': entry[\"output\"]\n",
    "    })\n",
    "    few_shot.append(new_entry)\n",
    "dump_json(few_shot, './stru_data/matching_few_shot/test_1k.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def few_shot(path):\n",
    "    test_data = load_json('{}/test_1k.json'.format(path))\n",
    "    try:\n",
    "        train_data = load_json('{}/train_10k.json'.format(path))\n",
    "    except:\n",
    "        train_data = load_json('./stru_data/matching/train_10k.json'.format(path))\n",
    "    few_shot = []\n",
    "    for index, entry in enumerate(test_data):\n",
    "        new_entry = {}\n",
    "        new_entry['instruction'] = entry['instruction']\n",
    "        new_entry['example'] = json.dumps({\n",
    "            'input': train_data[index]['input'],\n",
    "            'output': train_data[index]['output']\n",
    "        })\n",
    "        new_entry['test example'] = json.dumps({\n",
    "            'input': entry['input'],\n",
    "            'output': entry[\"output\"]\n",
    "        })\n",
    "        few_shot.append(new_entry)\n",
    "    if not os.path.exists('{}_few_shot'.format(path)):\n",
    "        os.makedirs('{}_few_shot'.format(path))\n",
    "    dump_json(few_shot, '{}_few_shot/test_1k.json'.format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot('./stru_data/matching')\n",
    "few_shot('./stru_data/matching_di')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm4rec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
