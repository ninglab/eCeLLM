{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "seed = 1\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "def load_pickle(addr):\n",
    "    with open(addr, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "def dump_pickle(data, addr):\n",
    "    with open(addr, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "def load_json(addr):\n",
    "    with open(addr, 'r') as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "def dump_json(data, addr):\n",
    "    with open(addr, 'w') as f:\n",
    "        json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')       \n",
    "    for l in g:\n",
    "        yield json.loads(l)\n",
    "\n",
    "def getgz(path):\n",
    "    id2item = {}\n",
    "    for d in parse(path):\n",
    "        id2item[d['asin']] = d\n",
    "    return id2item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'001212835X': {'category': ['Tools & Home Improvement',\n",
       "   'Lighting & Ceiling Fans',\n",
       "   'Lamps & Shades',\n",
       "   'Table Lamps'],\n",
       "  'tech1': '',\n",
       "  'description': ['collectible table lamp'],\n",
       "  'fit': '',\n",
       "  'title': \"Everett's Cottage Table Lamp\",\n",
       "  'also_buy': [],\n",
       "  'tech2': '',\n",
       "  'brand': '',\n",
       "  'feature': [],\n",
       "  'rank': ['>#3,780,135 in Tools & Home Improvement (See top 100)',\n",
       "   '>#45,028 in Tools & Home Improvement > Lighting & Ceiling Fans > Lamps & Shades > Table Lamps'],\n",
       "  'also_view': [],\n",
       "  'main_cat': 'Tools & Home Improvement',\n",
       "  'similar_item': '',\n",
       "  'date': 'October 30, 2010',\n",
       "  'price': '',\n",
       "  'asin': '001212835X',\n",
       "  'imageURL': [],\n",
       "  'imageURLHighRes': []}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getgz('./datasets/Amazon_review/meta/all_category/meta_Tools_and_Home_Improvement.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "def process_pairs(id, rawdata, mode):\n",
    "    try:\n",
    "        item = rawdata[id]\n",
    "        if mode == 0:\n",
    "            candidates = item['also_buy']\n",
    "        elif mode == 1:\n",
    "            candidates = item['also_view']\n",
    "        else:\n",
    "            candidates = [i[1:11] for i in item['similar_item'].split('asin')]\n",
    "        pairs = set()\n",
    "        for cand in candidates:\n",
    "            if id != cand and cand in rawdata and item['title'] != rawdata[cand]['title']:\n",
    "                pairs.add(tuple(sorted([item['title'], rawdata[cand]['title']])))    \n",
    "        return pairs\n",
    "    except:\n",
    "        return set()\n",
    "\n",
    "def process_rawdata(addr):\n",
    "    rawdata = getgz(addr)\n",
    "    processed_data = []\n",
    "    also_buys, also_views, similars = set(), set(), set()\n",
    "    for id in tqdm(rawdata):\n",
    "        also_buys |= process_pairs(id, rawdata, 0)\n",
    "        also_views |= process_pairs(id, rawdata, 1)\n",
    "        similars |= process_pairs(id, rawdata, 2)\n",
    "    comb_set = list(also_buys | also_views | similars)\n",
    "    for pair in comb_set:\n",
    "        label = -1\n",
    "        if pair in also_buys:\n",
    "            label = 0\n",
    "        if pair in also_views:\n",
    "            if label != -1:\n",
    "                continue\n",
    "            label = 1\n",
    "        if pair in similars:\n",
    "            if label != -1:\n",
    "                continue\n",
    "            label = 2\n",
    "        processed_data.append([pair[0], pair[1], label])\n",
    "    return processed_data\n",
    "\n",
    "def process_stru_split(data, size):\n",
    "    stru_data = []\n",
    "    for pair in data:\n",
    "        if len(stru_data) == size:\n",
    "            break\n",
    "        new_entry = {}\n",
    "        new_entry['instruction'] = \"Given the title of two products, predict if the two products are similar, if the two products will be purchased or viewed together. Answer only from the options.\"\n",
    "        new_entry[\"input\"] = json.dumps({\n",
    "            \"Product 1:\": pair[0],\n",
    "            \"Product 2:\": pair[1]\n",
    "        })\n",
    "        new_entry[\"options\"] = json.dumps([\n",
    "            \"A: Users who buy product 1 may also buy product 2.\",\n",
    "            \"B: Users who view product 1 may also view product 2.\",\n",
    "            \"C: The product 1 is similar with the product 2.\"\n",
    "        ])\n",
    "        new_entry[\"output\"] = chr(pair[2] + ord('A'))\n",
    "        stru_data.append(new_entry)\n",
    "    return stru_data\n",
    "\n",
    "def process_stru_data(addr, train_size, val_size, test_size, ood=False):\n",
    "    processed_data = process_rawdata(addr)\n",
    "    train, val_test = train_test_split(processed_data, test_size=0.2, random_state=seed)\n",
    "    val, test = train_test_split(val_test, test_size=0.5, random_state=seed)\n",
    "    print(train[0])\n",
    "    print(test[0])\n",
    "    rawdir = './raw_data/final_version/{}'.format(addr.split('/')[-1][5:-8])\n",
    "    if not os.path.exists(rawdir):\n",
    "        os.makedirs(rawdir)\n",
    "    dump_pickle(train, '{}/train.pickle'.format(rawdir))\n",
    "    dump_pickle(val, '{}/val.pickle'.format(rawdir))\n",
    "    dump_pickle(test, '{}/test.pickle'.format(rawdir))\n",
    "    dir = './stru_data/in_cat/relation_prediction_{}'.format(addr.split('/')[-1][5:-8])\n",
    "    if ood:\n",
    "        dir = './stru_data/relation_prediction_OOD'\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "    if not ood:\n",
    "        stru_train = process_stru_split(train, train_size)\n",
    "        stru_val = process_stru_split(val, val_size)\n",
    "        dump_json(stru_train, '{}/train_{}k.json'.format(dir, len(stru_train)//1000))\n",
    "        dump_json(stru_val, '{}/val_{}k.json'.format(dir, len(stru_val)//1000))\n",
    "    stru_test = process_stru_split(test, test_size)\n",
    "    dump_json(stru_test, '{}/test_{}k.json'.format(dir, len(stru_test)//1000))\n",
    "\n",
    "def process_mix_data(cats, train_size, val_size, test_size):\n",
    "    trains, vals, tests = [], [], []\n",
    "    for cat in cats:\n",
    "        dir = './stru_data/in_cat/relation_prediction_{}'.format(cat)\n",
    "        if not os.path.exists(dir):\n",
    "            process_stru_data('./datasets/Amazon_review/meta/all_category/meta_{}.json.gz'.format(cat), train_size, val_size, test_size)\n",
    "        trains += load_json('{}/train_10k.json'.format(dir))\n",
    "        vals += load_json('{}/val_1k.json'.format(dir))\n",
    "        tests += load_json('{}/test_1k.json'.format(dir))\n",
    "    mix_train = random.sample(trains, k=train_size)\n",
    "    mix_val = random.sample(vals, k=val_size)\n",
    "    mix_test = random.sample(tests, k=test_size)\n",
    "    print(mix_train[0]['input'])\n",
    "    print(mix_test[0]['input'])\n",
    "    dump_json(mix_train, './stru_data/relation_prediction_mix/train_{}k.json'.format(len(mix_train)//1000))\n",
    "    dump_json(mix_val, './stru_data/relation_prediction_mix/val_{}k.json'.format(len(mix_val)//1000))\n",
    "    dump_json(mix_test, './stru_data/relation_prediction_mix/test_{}k.json'.format(len(mix_test)//1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Product 1:\": \"Cooler Master HAF X - Full Tower Computer Case with USB 3.0 Ports and Windowed Side Panel (RC-942-KKN1)\", \"Product 2:\": \"G.Skill Ripjaws V Series 16GB (2 x 8GB) 288-Pin SDRAM DDR4 3200 (PC4 25600) Intel Z170 Desktop Memory F4-3200C16D-16GVGB\"}\n",
      "{\"Product 1:\": \"Cerwin-Vega XED52 Speaker 275 W PMPO 2-Way, 2 Count, Black\", \"Product 2:\": \"Rockford R169X2 6 x 9 Inches Full Range Coaxial Speaker, Set of 2\"}\n"
     ]
    }
   ],
   "source": [
    "# train, val, and IND test sets\n",
    "random.seed(seed)\n",
    "train_size, val_size, test_size = 10000, 1000, 1000\n",
    "process_mix_data([\"Electronics\",\"Home_and_Kitchen\",\"Sports_and_Outdoors\"], train_size, val_size, test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Product 1:\": \"Cooler Master HAF X - Full Tower Computer Case with USB 3.0 Ports and Windowed Side Panel (RC-942-KKN1)\", \"Product 2:\": \"G.Skill Ripjaws V Series 16GB (2 x 8GB) 288-Pin SDRAM DDR4 3200 (PC4 25600) Intel Z170 Desktop Memory F4-3200C16D-16GVGB\"}\n",
      "{\"Product 1:\": \"Cerwin-Vega XED52 Speaker 275 W PMPO 2-Way, 2 Count, Black\", \"Product 2:\": \"Rockford R169X2 6 x 9 Inches Full Range Coaxial Speaker, Set of 2\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 559340/559340 [00:11<00:00, 47491.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1866414\n",
      "1625725\n",
      "['18&quot; Wire Burner 3 Piece Set', 'Anchorseal 1 gal, 2 Green Wood Sealer Gallon', 0]\n",
      "['DEWALT Drill/Driver Set, 80-Piece  (DW2587)', 'DeWalt (2 Pack) Bit Holder for 20V Max DCD980 DCD985 DCD980L2 DCD985L2 # N131745-2pk', 0]\n"
     ]
    }
   ],
   "source": [
    "# OOD test set\n",
    "random.seed(seed)\n",
    "train_size, val_size, test_size = 10000, 1000, 1000\n",
    "process_mix_data([\"Electronics\",\"Home_and_Kitchen\",\"Sports_and_Outdoors\"], train_size, val_size, test_size)\n",
    "process_stru_data('./datasets/Amazon_review/meta/all_category/meta_Tools_and_Home_Improvement.json.gz', train_size, val_size, test_size, ood=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## diverse instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diverse_instruction(path, instrs, unseen):\n",
    "    for file in os.listdir(path):\n",
    "        data = load_json(os.path.join(path, file))\n",
    "        for entry in data:\n",
    "            entry[\"instruction\"] = random.sample(instrs, k=1)[0]\n",
    "        if not os.path.exists(os.path.join('{}_di'.format(path))):\n",
    "            os.makedirs(os.path.join('{}_di'.format(path)))\n",
    "        dump_json(data, os.path.join('{}_di'.format(path), file))\n",
    "    \n",
    "        if file.startswith('test'):\n",
    "            for entry in data:\n",
    "                entry[\"instruction\"] = unseen\n",
    "            if not os.path.exists(os.path.join('{}_ui'.format(path))):\n",
    "                os.makedirs(os.path.join('{}_ui'.format(path)))\n",
    "            dump_json(data, os.path.join('{}_ui'.format(path), file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyze the titles of Product 1 and Product 2 and select the option that indicates the relation of the two products.\n"
     ]
    }
   ],
   "source": [
    "random.seed(seed)\n",
    "instrs = [\n",
    "    \"Analyze the titles of Product 1 and Product 2 to determine if they are similar, if they will be purchased or viewed together, and choose the corresponding option.\",\n",
    "\"Analyze the titles of Product 1 and Product 2 and select the option that indicates the relation of the two products.\",\n",
    "\"Evaluate the titles of Product 1 and Product 2, then choose the option that best describes the relation between the two products.\",\n",
    "\"Evaluate the titles of Product 1 and Product 2 to assess their similarity and whether they are likely to be purchased or viewed together. Then, select the appropriate option.\",\n",
    "\"Predict whether two products are similar, whether two products are likely to be purchased or viewed together based on their titles. Choose your answer from the provided options.\"\n",
    "]\n",
    "unseen = random.sample(instrs, k=1)[0]\n",
    "instrs.remove(unseen)\n",
    "print(unseen)\n",
    "instrs.append(\"Given the title of two products, predict if the two products are similar, if the two products will be purchased or viewed together. Answer only from the options.\")\n",
    "diverse_instruction('./stru_data/relation_prediction_mix', instrs, unseen)\n",
    "diverse_instruction('./stru_data/relation_prediction_OOD', instrs, unseen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## few-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def few_shot(path):\n",
    "    test_data = load_json('{}/test_1k.json'.format(path))\n",
    "    try:\n",
    "        train_data = load_json('{}/train_10k.json'.format(path))\n",
    "    except:\n",
    "        train_data = load_json('./stru_data/relation_prediction_mix/train_10k.json')\n",
    "    few_shot = []\n",
    "    for index, entry in enumerate(test_data):\n",
    "        new_entry = {}\n",
    "        new_entry['instruction'] = entry['instruction']\n",
    "        new_entry['example'] = json.dumps({\n",
    "            'input': train_data[index]['input'],\n",
    "            'options': train_data[index]['options'],\n",
    "            'output': train_data[index]['output']\n",
    "        })\n",
    "        new_entry['test example'] = json.dumps({\n",
    "            'input': entry['input'],\n",
    "            'options': entry['options'],\n",
    "            'output': entry[\"output\"]\n",
    "        })\n",
    "        few_shot.append(new_entry)\n",
    "    if not os.path.exists('{}_few_shot'.format(path)):\n",
    "        os.makedirs('{}_few_shot'.format(path))\n",
    "    dump_json(few_shot, '{}_few_shot/test_1k.json'.format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot('./stru_data/relation_prediction_mix')\n",
    "few_shot('./stru_data/relation_prediction_mix_di')\n",
    "few_shot('./stru_data/relation_prediction_OOD')\n",
    "few_shot('./stru_data/relation_prediction_OOD_di')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm4rec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
